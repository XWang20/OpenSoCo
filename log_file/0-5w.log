{\rtf1\ansi\ansicpg1252\cocoartf2706
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fnil\fcharset0 HelveticaNeue;}
{\colortbl;\red255\green255\blue255;\red0\green0\blue0;\red245\green245\blue245;}
{\*\expandedcolortbl;;\cssrgb\c0\c0\c0\c65098;\cssrgb\c96863\c96863\c96863;}
\paperw11900\paperh16840\margl1440\margr1440\vieww11520\viewh8400\viewkind0
\deftab720
\pard\pardeftab720\sa28\partightenfactor0

\f0\fs28 \cf2 \cb3 \expnd0\expndtw0\kerning0
2023-07-11 23:13:00 | Iter: 0 | valid loss: 11.0375\cb1 \
\cb3 Gradient overflow, change scale from 524288.000000 to 262144.000000\cb1 \
\cb3 Gradient overflow, change scale from 262144.000000 to 131072.000000\cb1 \
\cb3 2023-07-11 23:15:19 | Iter: 100 | loss: 10.1268 | lr: 9.8000e-07, scale: 131072.0000 | grad_norm: 3.6249\cb1 \
\cb3 2023-07-11 23:17:36 | Iter: 200 | loss: 8.9008 | lr: 1.9800e-06, scale: 131072.0000 | grad_norm: 2.8756\cb1 \
\cb3 2023-07-11 23:19:52 | Iter: 300 | loss: 8.4860 | lr: 2.9800e-06, scale: 131072.0000 | grad_norm: 2.9914\cb1 \
\cb3 2023-07-11 23:22:08 | Iter: 400 | loss: 8.0702 | lr: 3.9800e-06, scale: 131072.0000 | grad_norm: 2.9226\cb1 \
\cb3 2023-07-11 23:24:23 | Iter: 500 | loss: 7.6747 | lr: 4.9800e-06, scale: 131072.0000 | grad_norm: 3.7099\cb1 \
\cb3 start valid!\cb1 \
\cb3 2023-07-11 23:24:39 | Iter: 500 | valid loss: 7.4735\cb1 \
\cb3 saving status into: /data/checkpoints/checkpoint-500.success\cb1 \
\cb3 Saving checkpoint at 500 step.\cb1 \
\cb3 2023-07-11 23:27:08 | Iter: 600 | loss: 7.3499 | lr: 5.9800e-06, scale: 131072.0000 | grad_norm: 2.4682\cb1 \
\cb3 2023-07-11 23:29:24 | Iter: 700 | loss: 7.1612 | lr: 6.9800e-06, scale: 131072.0000 | grad_norm: 2.9831\cb1 \
\cb3 2023-07-11 23:31:41 | Iter: 800 | loss: 7.0541 | lr: 7.9800e-06, scale: 131072.0000 | grad_norm: 3.6711\cb1 \
\cb3 2023-07-11 23:33:58 | Iter: 900 | loss: 6.9696 | lr: 8.9800e-06, scale: 131072.0000 | grad_norm: 3.3546\cb1 \
\cb3 2023-07-11 23:36:13 | Iter: 1000 | loss: 6.9014 | lr: 9.9800e-06, scale: 131072.0000 | grad_norm: 3.3469\cb1 \
\cb3 start valid!\cb1 \
\cb3 2023-07-11 23:36:30 | Iter: 1000 | valid loss: 6.8503\cb1 \
\cb3 saving status into: /data/checkpoints/checkpoint-1000.success\cb1 \
\cb3 Saving checkpoint at 1000 step.\cb1 \
\cb3 Gradient overflow, change scale from 262144.000000 to 131072.000000\cb1 \
\cb3 2023-07-11 23:38:56 | Iter: 1100 | loss: 6.8298 | lr: 1.0970e-05, scale: 131072.0000 | grad_norm: 2.8134\cb1 \
\cb3 2023-07-11 23:41:14 | Iter: 1200 | loss: 6.7591 | lr: 1.1970e-05, scale: 131072.0000 | grad_norm: 3.4600\cb1 \
\cb3 2023-07-11 23:43:29 | Iter: 1300 | loss: 6.6953 | lr: 1.2970e-05, scale: 131072.0000 | grad_norm: 4.0624\cb1 \
\cb3 2023-07-11 23:45:45 | Iter: 1400 | loss: 6.6327 | lr: 1.3970e-05, scale: 131072.0000 | grad_norm: 2.6509\cb1 \
\cb3 2023-07-11 23:48:03 | Iter: 1500 | loss: 6.5809 | lr: 1.4970e-05, scale: 131072.0000 | grad_norm: 3.8377\cb1 \
\cb3 start valid!\cb1 \
\cb3 2023-07-11 23:48:18 | Iter: 1500 | valid loss: 6.5249\cb1 \
\cb3 saving status into: /data/checkpoints/checkpoint-1500.success\cb1 \
\cb3 Saving checkpoint at 1500 step.\cb1 \
\cb3 2023-07-11 23:50:48 | Iter: 1600 | loss: 6.5385 | lr: 1.5970e-05, scale: 131072.0000 | grad_norm: 3.4225\cb1 \
\cb3 2023-07-11 23:53:06 | Iter: 1700 | loss: 6.5038 | lr: 1.6970e-05, scale: 131072.0000 | grad_norm: 3.1874\cb1 \
\cb3 2023-07-11 23:55:21 | Iter: 1800 | loss: 6.4708 | lr: 1.7970e-05, scale: 131072.0000 | grad_norm: 3.8540\cb1 \
\cb3 2023-07-11 23:57:38 | Iter: 1900 | loss: 6.4381 | lr: 1.8970e-05, scale: 131072.0000 | grad_norm: 3.0258\cb1 \
\cb3 2023-07-11 23:59:54 | Iter: 2000 | loss: 6.4158 | lr: 1.9970e-05, scale: 131072.0000 | grad_norm: 3.9126\cb1 \
\cb3 start valid!\cb1 \
\cb3 2023-07-12 00:00:12 | Iter: 2000 | valid loss: 6.3801\cb1 \
\cb3 saving status into: /data/checkpoints/checkpoint-2000.success\cb1 \
\cb3 Saving checkpoint at 2000 step.\cb1 \
\cb3 Gradient overflow, change scale from 262144.000000 to 131072.000000\cb1 \
\cb3 2023-07-12 00:02:44 | Iter: 2100 | loss: 6.3981 | lr: 2.0960e-05, scale: 131072.0000 | grad_norm: 2.7881\cb1 \
\cb3 2023-07-12 00:04:58 | Iter: 2200 | loss: 6.3769 | lr: 2.1960e-05, scale: 131072.0000 | grad_norm: 3.2699\cb1 \
\cb3 2023-07-12 00:07:16 | Iter: 2300 | loss: 6.3640 | lr: 2.2960e-05, scale: 131072.0000 | grad_norm: 4.3635\cb1 \
\cb3 2023-07-12 00:09:33 | Iter: 2400 | loss: 6.3496 | lr: 2.3960e-05, scale: 131072.0000 | grad_norm: 3.0300\cb1 \
\cb3 2023-07-12 00:11:49 | Iter: 2500 | loss: 6.3340 | lr: 2.4960e-05, scale: 131072.0000 | grad_norm: 2.3855\cb1 \
\cb3 start valid!\cb1 \
\cb3 2023-07-12 00:12:05 | Iter: 2500 | valid loss: 6.3016\cb1 \
\cb3 saving status into: /data/checkpoints/checkpoint-2500.success\cb1 \
\cb3 Saving checkpoint at 2500 step.\cb1 \
\cb3 2023-07-12 00:14:35 | Iter: 2600 | loss: 6.3202 | lr: 2.5960e-05, scale: 131072.0000 | grad_norm: 2.3142\cb1 \
\cb3 2023-07-12 00:16:53 | Iter: 2700 | loss: 6.3108 | lr: 2.6960e-05, scale: 131072.0000 | grad_norm: 2.3600\cb1 \
\cb3 2023-07-12 00:19:12 | Iter: 2800 | loss: 6.2993 | lr: 2.7960e-05, scale: 131072.0000 | grad_norm: 3.0701\cb1 \
\cb3 2023-07-12 00:21:29 | Iter: 2900 | loss: 6.2916 | lr: 2.8960e-05, scale: 131072.0000 | grad_norm: 3.0554\cb1 \
\cb3 2023-07-12 00:23:46 | Iter: 3000 | loss: 6.2833 | lr: 2.9960e-05, scale: 131072.0000 | grad_norm: 2.5721\cb1 \
\cb3 start valid!\cb1 \
\cb3 2023-07-12 00:24:02 | Iter: 3000 | valid loss: 6.2601\cb1 \
\cb3 saving status into: /data/checkpoints/checkpoint-3000.success\cb1 \
\cb3 Saving checkpoint at 3000 step.\cb1 \
\cb3 Gradient overflow, change scale from 131072.000000 to 65536.000000\cb1 \
\cb3 2023-07-12 00:26:28 | Iter: 3100 | loss: 6.2764 | lr: 3.0950e-05, scale: 65536.0000 | grad_norm: 2.9138\cb1 \
\cb3 2023-07-12 00:28:45 | Iter: 3200 | loss: 6.2649 | lr: 3.1950e-05, scale: 65536.0000 | grad_norm: 2.0426\cb1 \
\cb3 2023-07-12 00:30:59 | Iter: 3300 | loss: 6.2592 | lr: 3.2950e-05, scale: 65536.0000 | grad_norm: 2.4346\cb1 \
\cb3 2023-07-12 00:33:16 | Iter: 3400 | loss: 6.2539 | lr: 3.3950e-05, scale: 65536.0000 | grad_norm: 2.3025\cb1 \
\cb3 2023-07-12 00:35:29 | Iter: 3500 | loss: 6.2423 | lr: 3.4950e-05, scale: 65536.0000 | grad_norm: 2.9497\cb1 \
\cb3 start valid!\cb1 \
\cb3 2023-07-12 00:35:46 | Iter: 3500 | valid loss: 6.2195\cb1 \
\cb3 saving status into: /data/checkpoints/checkpoint-3500.success\cb1 \
\cb3 Saving checkpoint at 3500 step.\cb1 \
\cb3 2023-07-12 00:38:13 | Iter: 3600 | loss: 6.2412 | lr: 3.5950e-05, scale: 65536.0000 | grad_norm: 2.2766\cb1 \
\cb3 2023-07-12 00:40:26 | Iter: 3700 | loss: 6.2361 | lr: 3.6950e-05, scale: 65536.0000 | grad_norm: 2.4932\cb1 \
\cb3 2023-07-12 00:42:42 | Iter: 3800 | loss: 6.2267 | lr: 3.7950e-05, scale: 65536.0000 | grad_norm: 1.9610\cb1 \
\cb3 2023-07-12 00:44:55 | Iter: 3900 | loss: 6.2217 | lr: 3.8950e-05, scale: 65536.0000 | grad_norm: 1.8928\cb1 \
\cb3 2023-07-12 00:47:10 | Iter: 4000 | loss: 6.2207 | lr: 3.9950e-05, scale: 65536.0000 | grad_norm: 1.8262\cb1 \
\cb3 start valid!\cb1 \
\cb3 2023-07-12 00:47:26 | Iter: 4000 | valid loss: 6.1931\cb1 \
\cb3 saving status into: /data/checkpoints/checkpoint-4000.success\cb1 \
\cb3 Saving checkpoint at 4000 step.\cb1 \
\cb3 2023-07-12 00:49:51 | Iter: 4100 | loss: 6.2158 | lr: 4.0950e-05, scale: 131072.0000 | grad_norm: 1.6438\cb1 \
\cb3 2023-07-12 00:52:05 | Iter: 4200 | loss: 6.2087 | lr: 4.1950e-05, scale: 131072.0000 | grad_norm: 1.8695\cb1 \
\cb3 2023-07-12 00:54:18 | Iter: 4300 | loss: 6.2069 | lr: 4.2950e-05, scale: 131072.0000 | grad_norm: 2.0244\cb1 \
\cb3 2023-07-12 00:56:32 | Iter: 4400 | loss: 6.2030 | lr: 4.3950e-05, scale: 131072.0000 | grad_norm: 1.6633\cb1 \
\cb3 2023-07-12 00:58:46 | Iter: 4500 | loss: 6.1963 | lr: 4.4950e-05, scale: 131072.0000 | grad_norm: 2.2083\cb1 \
\cb3 start valid!\cb1 \
\cb3 2023-07-12 00:59:02 | Iter: 4500 | valid loss: 6.1778\cb1 \
\cb3 saving status into: /data/checkpoints/checkpoint-4500.success\cb1 \
\cb3 Saving checkpoint at 4500 step.\cb1 \
\cb3 2023-07-12 01:01:28 | Iter: 4600 | loss: 6.1937 | lr: 4.5950e-05, scale: 131072.0000 | grad_norm: 2.1870\cb1 \
\cb3 2023-07-12 01:03:44 | Iter: 4700 | loss: 6.1818 | lr: 4.6950e-05, scale: 131072.0000 | grad_norm: 2.0506\cb1 \
\cb3 2023-07-12 01:06:00 | Iter: 4800 | loss: 6.1417 | lr: 4.7950e-05, scale: 131072.0000 | grad_norm: 2.0499\cb1 \
\cb3 2023-07-12 01:08:13 | Iter: 4900 | loss: 6.0700 | lr: 4.8950e-05, scale: 131072.0000 | grad_norm: 2.3507\cb1 \
\cb3 2023-07-12 01:10:26 | Iter: 5000 | loss: 5.7770 | lr: 4.9950e-05, scale: 131072.0000 | grad_norm: 3.2139\cb1 \
\cb3 start valid!\cb1 \
\cb3 2023-07-12 01:10:44 | Iter: 5000 | valid loss: 5.4663\cb1 \
\cb3 saving status into: /data/checkpoints/checkpoint-5000.success\cb1 \
\cb3 Saving checkpoint at 5000 step.\cb1 \
\cb3 Gradient overflow, change scale from 262144.000000 to 131072.000000\cb1 \
\cb3 2023-07-12 01:13:11 | Iter: 5100 | loss: 5.3730 | lr: 5.0940e-05, scale: 131072.0000 | grad_norm: 2.2847\cb1 \
\cb3 2023-07-12 01:15:26 | Iter: 5200 | loss: 5.0885 | lr: 5.1940e-05, scale: 131072.0000 | grad_norm: 2.2038\cb1 \
\cb3 2023-07-12 01:17:44 | Iter: 5300 | loss: 4.8203 | lr: 5.2940e-05, scale: 131072.0000 | grad_norm: 2.5526\cb1 \
\cb3 2023-07-12 01:19:56 | Iter: 5400 | loss: 4.6099 | lr: 5.3940e-05, scale: 131072.0000 | grad_norm: 2.4980\cb1 \
\cb3 2023-07-12 01:22:12 | Iter: 5500 | loss: 4.4589 | lr: 5.4940e-05, scale: 131072.0000 | grad_norm: 1.9927\cb1 \
\cb3 start valid!\cb1 \
\cb3 2023-07-12 01:22:28 | Iter: 5500 | valid loss: 4.2514\cb1 \
\cb3 saving status into: /data/checkpoints/checkpoint-5500.success\cb1 \
\cb3 Saving checkpoint at 5500 step.\cb1 \
\cb3 2023-07-12 01:24:56 | Iter: 5600 | loss: 4.3311 | lr: 5.5940e-05, scale: 131072.0000 | grad_norm: 1.8471\cb1 \
\cb3 2023-07-12 01:27:12 | Iter: 5700 | loss: 4.2212 | lr: 5.6940e-05, scale: 131072.0000 | grad_norm: 1.8824\cb1 \
\cb3 2023-07-12 01:29:26 | Iter: 5800 | loss: 4.1267 | lr: 5.7940e-05, scale: 131072.0000 | grad_norm: 1.9506\cb1 \
\cb3 2023-07-12 01:31:41 | Iter: 5900 | loss: 4.0419 | lr: 5.8940e-05, scale: 131072.0000 | grad_norm: 2.1473\cb1 \
\cb3 2023-07-12 01:33:56 | Iter: 6000 | loss: 3.9619 | lr: 5.9940e-05, scale: 131072.0000 | grad_norm: 1.8874\cb1 \
\cb3 start valid!\cb1 \
\cb3 2023-07-12 01:34:12 | Iter: 6000 | valid loss: 3.8021\cb1 \
\cb3 saving status into: /data/checkpoints/checkpoint-6000.success\cb1 \
\cb3 Saving checkpoint at 6000 step.\cb1 \
\cb3 Gradient overflow, change scale from 262144.000000 to 131072.000000\cb1 \
\cb3 2023-07-12 01:36:38 | Iter: 6100 | loss: 3.8913 | lr: 6.0930e-05, scale: 131072.0000 | grad_norm: inf\cb1 \
\cb3 2023-07-12 01:38:52 | Iter: 6200 | loss: 3.8248 | lr: 6.1930e-05, scale: 131072.0000 | grad_norm: 1.8126\cb1 \
\cb3 2023-07-12 01:41:06 | Iter: 6300 | loss: 3.7592 | lr: 6.2930e-05, scale: 131072.0000 | grad_norm: 1.5126\cb1 \
\cb3 2023-07-12 01:43:21 | Iter: 6400 | loss: 3.7064 | lr: 6.3930e-05, scale: 131072.0000 | grad_norm: 1.7332\cb1 \
\cb3 2023-07-12 01:45:36 | Iter: 6500 | loss: 3.6323 | lr: 6.4930e-05, scale: 131072.0000 | grad_norm: 1.7646\cb1 \
\cb3 start valid!\cb1 \
\cb3 2023-07-12 01:45:52 | Iter: 6500 | valid loss: 3.5039\cb1 \
\cb3 saving status into: /data/checkpoints/checkpoint-6500.success\cb1 \
\cb3 Saving checkpoint at 6500 step.\cb1 \
\cb3 2023-07-12 01:48:17 | Iter: 6600 | loss: 3.5812 | lr: 6.5930e-05, scale: 131072.0000 | grad_norm: 1.7851\cb1 \
\cb3 2023-07-12 01:50:34 | Iter: 6700 | loss: 3.5163 | lr: 6.6930e-05, scale: 131072.0000 | grad_norm: 1.6092\cb1 \
\cb3 2023-07-12 01:52:49 | Iter: 6800 | loss: 3.4490 | lr: 6.7930e-05, scale: 131072.0000 | grad_norm: 1.7190\cb1 \
\cb3 2023-07-12 01:55:03 | Iter: 6900 | loss: 3.3699 | lr: 6.8930e-05, scale: 131072.0000 | grad_norm: 1.6221\cb1 \
\cb3 2023-07-12 01:57:19 | Iter: 7000 | loss: 3.2921 | lr: 6.9930e-05, scale: 131072.0000 | grad_norm: 1.7262\cb1 \
\cb3 start valid!\cb1 \
\cb3 2023-07-12 01:57:37 | Iter: 7000 | valid loss: 3.1473\cb1 \
\cb3 saving status into: /data/checkpoints/checkpoint-7000.success\cb1 \
\cb3 Saving checkpoint at 7000 step.\cb1 \
\cb3 2023-07-12 02:00:01 | Iter: 7100 | loss: 3.2387 | lr: 7.0930e-05, scale: 131072.0000 | grad_norm: 1.6587\cb1 \
\cb3 2023-07-12 02:02:25 | Iter: 7200 | loss: 3.1942 | lr: 7.1930e-05, scale: 262144.0000 | grad_norm: 1.6809\cb1 \
\cb3 2023-07-12 02:04:39 | Iter: 7300 | loss: 3.1570 | lr: 7.2930e-05, scale: 262144.0000 | grad_norm: 1.7364\cb1 \
\cb3 Gradient overflow, change scale from 262144.000000 to 131072.000000\cb1 \
\cb3 2023-07-12 02:06:54 | Iter: 7400 | loss: 3.1011 | lr: 7.3920e-05, scale: 131072.0000 | grad_norm: 1.5465\cb1 \
\cb3 2023-07-12 02:09:09 | Iter: 7500 | loss: 3.0678 | lr: 7.4920e-05, scale: 131072.0000 | grad_norm: 1.4119\cb1 \
\cb3 start valid!\cb1 \
\cb3 2023-07-12 02:09:24 | Iter: 7500 | valid loss: 2.9428\cb1 \
\cb3 saving status into: /data/checkpoints/checkpoint-7500.success\cb1 \
\cb3 Saving checkpoint at 7500 step.\cb1 \
\cb3 2023-07-12 02:11:52 | Iter: 7600 | loss: 3.0256 | lr: 7.5920e-05, scale: 131072.0000 | grad_norm: 1.4885\cb1 \
\cb3 2023-07-12 02:14:07 | Iter: 7700 | loss: 2.9954 | lr: 7.6920e-05, scale: 131072.0000 | grad_norm: 1.5693\cb1 \
\cb3 2023-07-12 02:16:20 | Iter: 7800 | loss: 2.9634 | lr: 7.7920e-05, scale: 131072.0000 | grad_norm: 1.8140\cb1 \
\cb3 2023-07-12 02:18:34 | Iter: 7900 | loss: 2.9313 | lr: 7.8920e-05, scale: 131072.0000 | grad_norm: 1.7444\cb1 \
\cb3 2023-07-12 02:20:50 | Iter: 8000 | loss: 2.8881 | lr: 7.9920e-05, scale: 131072.0000 | grad_norm: 1.5264\cb1 \
\cb3 start valid!\cb1 \
\cb3 2023-07-12 02:21:05 | Iter: 8000 | valid loss: 2.7914\cb1 \
\cb3 saving status into: /data/checkpoints/checkpoint-8000.success\cb1 \
\cb3 Saving checkpoint at 8000 step.\cb1 \
\cb3 2023-07-12 02:23:31 | Iter: 8100 | loss: 2.8717 | lr: 8.0920e-05, scale: 131072.0000 | grad_norm: 1.6273\cb1 \
\cb3 2023-07-12 02:25:45 | Iter: 8200 | loss: 2.8383 | lr: 8.1920e-05, scale: 131072.0000 | grad_norm: 1.4431\cb1 \
\cb3 2023-07-12 02:28:01 | Iter: 8300 | loss: 2.8195 | lr: 8.2920e-05, scale: 131072.0000 | grad_norm: 1.3689\cb1 \
\cb3 2023-07-12 02:30:11 | Iter: 8400 | loss: 2.7856 | lr: 8.3920e-05, scale: 262144.0000 | grad_norm: 1.3327\cb1 \
\cb3 2023-07-12 02:32:23 | Iter: 8500 | loss: 2.7691 | lr: 8.4920e-05, scale: 262144.0000 | grad_norm: 1.5217\cb1 \
\cb3 start valid!\cb1 \
\cb3 2023-07-12 02:32:41 | Iter: 8500 | valid loss: 2.6714\cb1 \
\cb3 saving status into: /data/checkpoints/checkpoint-8500.success\cb1 \
\cb3 Saving checkpoint at 8500 step.\cb1 \
\cb3 2023-07-12 02:35:07 | Iter: 8600 | loss: 2.7367 | lr: 8.5920e-05, scale: 262144.0000 | grad_norm: 1.4826\cb1 \
\cb3 2023-07-12 02:37:21 | Iter: 8700 | loss: 2.7175 | lr: 8.6920e-05, scale: 262144.0000 | grad_norm: 1.5213\cb1 \
\cb3 2023-07-12 02:39:37 | Iter: 8800 | loss: 2.6892 | lr: 8.7920e-05, scale: 262144.0000 | grad_norm: 1.5445\cb1 \
\cb3 2023-07-12 02:41:51 | Iter: 8900 | loss: 2.6687 | lr: 8.8920e-05, scale: 262144.0000 | grad_norm: 1.7246\cb1 \
\cb3 2023-07-12 02:44:08 | Iter: 9000 | loss: 2.6483 | lr: 8.9920e-05, scale: 262144.0000 | grad_norm: 1.5660\cb1 \
\cb3 start valid!\cb1 \
\cb3 2023-07-12 02:44:25 | Iter: 9000 | valid loss: 2.5629\cb1 \
\cb3 saving status into: /data/checkpoints/checkpoint-9000.success\cb1 \
\cb3 Saving checkpoint at 9000 step.\cb1 \
\cb3 2023-07-12 02:46:53 | Iter: 9100 | loss: 2.6195 | lr: 9.0920e-05, scale: 262144.0000 | grad_norm: 1.5042\cb1 \
\cb3 2023-07-12 02:49:08 | Iter: 9200 | loss: 2.6082 | lr: 9.1920e-05, scale: 262144.0000 | grad_norm: 1.3621\cb1 \
\cb3 2023-07-12 02:51:20 | Iter: 9300 | loss: 2.5937 | lr: 9.2920e-05, scale: 262144.0000 | grad_norm: 1.4295\cb1 \
\cb3 Gradient overflow, change scale from 524288.000000 to 262144.000000\cb1 \
\cb3 2023-07-12 02:53:34 | Iter: 9400 | loss: 2.5741 | lr: 9.3910e-05, scale: 262144.0000 | grad_norm: 1.2733\cb1 \
\cb3 2023-07-12 02:55:48 | Iter: 9500 | loss: 2.5482 | lr: 9.4910e-05, scale: 262144.0000 | grad_norm: 1.6569\cb1 \
\cb3 start valid!\cb1 \
\cb3 2023-07-12 02:56:04 | Iter: 9500 | valid loss: 2.4545\cb1 \
\cb3 saving status into: /data/checkpoints/checkpoint-9500.success\cb1 \
\cb3 Saving checkpoint at 9500 step.\cb1 \
\cb3 2023-07-12 02:58:28 | Iter: 9600 | loss: 2.5311 | lr: 9.5910e-05, scale: 262144.0000 | grad_norm: 1.4456\cb1 \
\cb3 2023-07-12 03:00:44 | Iter: 9700 | loss: 2.5328 | lr: 9.6910e-05, scale: 262144.0000 | grad_norm: 1.4590\cb1 \
\cb3 2023-07-12 03:02:57 | Iter: 9800 | loss: 2.5045 | lr: 9.7910e-05, scale: 262144.0000 | grad_norm: 1.3253\cb1 \
\cb3 Gradient overflow, change scale from 262144.000000 to 131072.000000\cb1 \
\cb3 2023-07-12 03:05:11 | Iter: 9900 | loss: 2.4970 | lr: 9.8900e-05, scale: 131072.0000 | grad_norm: 1.6589\cb1 \
\cb3 2023-07-12 03:07:23 | Iter: 10000 | loss: 2.4680 | lr: 9.9900e-05, scale: 131072.0000 | grad_norm: 1.2917\cb1 \
\cb3 start valid!\cb1 \
\cb3 2023-07-12 03:07:41 | Iter: 10000 | valid loss: 2.3777\cb1 \
\cb3 saving status into: /data/checkpoints/checkpoint-10000.success\cb1 \
\cb3 Saving checkpoint at 10000 step.\cb1 \
\cb3 2023-07-12 03:10:06 | Iter: 10100 | loss: 2.4528 | lr: 9.9991e-05, scale: 131072.0000 | grad_norm: 1.5749\cb1 \
\cb3 2023-07-12 03:12:18 | Iter: 10200 | loss: 2.4416 | lr: 9.9981e-05, scale: 131072.0000 | grad_norm: 1.4310\cb1 \
\cb3 2023-07-12 03:14:33 | Iter: 10300 | loss: 2.4254 | lr: 9.9971e-05, scale: 131072.0000 | grad_norm: 1.4135\cb1 \
\cb3 2023-07-12 03:16:49 | Iter: 10400 | loss: 2.4119 | lr: 9.9961e-05, scale: 131072.0000 | grad_norm: 1.4346\cb1 \
\cb3 2023-07-12 03:19:02 | Iter: 10500 | loss: 2.3990 | lr: 9.9951e-05, scale: 131072.0000 | grad_norm: 1.3013\cb1 \
\cb3 start valid!\cb1 \
\cb3 2023-07-12 03:19:17 | Iter: 10500 | valid loss: 2.3267\cb1 \
\cb3 saving status into: /data/checkpoints/checkpoint-10500.success\cb1 \
\cb3 Saving checkpoint at 10500 step.\cb1 \
\cb3 2023-07-12 03:21:46 | Iter: 10600 | loss: 2.3839 | lr: 9.9940e-05, scale: 131072.0000 | grad_norm: 1.2999\cb1 \
\cb3 2023-07-12 03:24:00 | Iter: 10700 | loss: 2.3661 | lr: 9.9930e-05, scale: 131072.0000 | grad_norm: 1.4825\cb1 \
\cb3 2023-07-12 03:26:13 | Iter: 10800 | loss: 2.3462 | lr: 9.9920e-05, scale: 131072.0000 | grad_norm: 1.3031\cb1 \
\cb3 2023-07-12 03:28:27 | Iter: 10900 | loss: 2.3408 | lr: 9.9910e-05, scale: 131072.0000 | grad_norm: 1.3546\cb1 \
\cb3 2023-07-12 03:30:40 | Iter: 11000 | loss: 2.3298 | lr: 9.9900e-05, scale: 262144.0000 | grad_norm: 1.4282\cb1 \
\cb3 start valid!\cb1 \
\cb3 2023-07-12 03:30:56 | Iter: 11000 | valid loss: 2.2451\cb1 \
\cb3 saving status into: /data/checkpoints/checkpoint-11000.success\cb1 \
\cb3 Saving checkpoint at 11000 step.\cb1 \
\cb3 2023-07-12 03:33:21 | Iter: 11100 | loss: 2.3076 | lr: 9.9890e-05, scale: 262144.0000 | grad_norm: 1.3447\cb1 \
\cb3 2023-07-12 03:35:37 | Iter: 11200 | loss: 2.2970 | lr: 9.9880e-05, scale: 262144.0000 | grad_norm: 1.5057\cb1 \
\cb3 2023-07-12 03:37:52 | Iter: 11300 | loss: 2.2917 | lr: 9.9870e-05, scale: 262144.0000 | grad_norm: 1.2986\cb1 \
\cb3 2023-07-12 03:40:05 | Iter: 11400 | loss: 2.2828 | lr: 9.9860e-05, scale: 262144.0000 | grad_norm: 1.4088\cb1 \
\cb3 2023-07-12 03:42:21 | Iter: 11500 | loss: 2.2675 | lr: 9.9849e-05, scale: 262144.0000 | grad_norm: 1.2796\cb1 \
\cb3 start valid!\cb1 \
\cb3 2023-07-12 03:42:39 | Iter: 11500 | valid loss: 2.1801\cb1 \
\cb3 saving status into: /data/checkpoints/checkpoint-11500.success\cb1 \
\cb3 Saving checkpoint at 11500 step.\cb1 \
\cb3 2023-07-12 03:45:05 | Iter: 11600 | loss: 2.2582 | lr: 9.9839e-05, scale: 262144.0000 | grad_norm: 1.4019\cb1 \
\cb3 2023-07-12 03:47:19 | Iter: 11700 | loss: 2.2427 | lr: 9.9829e-05, scale: 262144.0000 | grad_norm: 1.5285\cb1 \
\cb3 2023-07-12 03:49:33 | Iter: 11800 | loss: 2.2300 | lr: 9.9819e-05, scale: 262144.0000 | grad_norm: 1.3656\cb1 \
\cb3 2023-07-12 03:51:46 | Iter: 11900 | loss: 2.2312 | lr: 9.9809e-05, scale: 262144.0000 | grad_norm: 1.3016\cb1 \
\cb3 Gradient overflow, change scale from 524288.000000 to 262144.000000\cb1 \
\cb3 2023-07-12 03:54:00 | Iter: 12000 | loss: 2.2103 | lr: 9.9799e-05, scale: 262144.0000 | grad_norm: 1.2161\cb1 \
\cb3 start valid!\cb1 \
\cb3 2023-07-12 03:54:16 | Iter: 12000 | valid loss: 2.1467\cb1 \
\cb3 saving status into: /data/checkpoints/checkpoint-12000.success\cb1 \
\cb3 Saving checkpoint at 12000 step.\cb1 \
\cb3 2023-07-12 03:56:46 | Iter: 12100 | loss: 2.2099 | lr: 9.9789e-05, scale: 262144.0000 | grad_norm: 1.2583\cb1 \
\cb3 2023-07-12 03:59:00 | Iter: 12200 | loss: 2.1959 | lr: 9.9779e-05, scale: 262144.0000 | grad_norm: 1.3788\cb1 \
\cb3 2023-07-12 04:01:16 | Iter: 12300 | loss: 2.1938 | lr: 9.9769e-05, scale: 262144.0000 | grad_norm: 1.2251\cb1 \
\cb3 2023-07-12 04:03:34 | Iter: 12400 | loss: 2.1817 | lr: 9.9759e-05, scale: 262144.0000 | grad_norm: 1.3855\cb1 \
\cb3 2023-07-12 04:05:47 | Iter: 12500 | loss: 2.1699 | lr: 9.9749e-05, scale: 262144.0000 | grad_norm: 1.4288\cb1 \
\cb3 start valid!\cb1 \
\cb3 2023-07-12 04:06:03 | Iter: 12500 | valid loss: 2.1031\cb1 \
\cb3 saving status into: /data/checkpoints/checkpoint-12500.success\cb1 \
\cb3 Saving checkpoint at 12500 step.\cb1 \
\cb3 2023-07-12 04:08:29 | Iter: 12600 | loss: 2.1621 | lr: 9.9738e-05, scale: 262144.0000 | grad_norm: 1.1960\cb1 \
\cb3 2023-07-12 04:10:47 | Iter: 12700 | loss: 2.1599 | lr: 9.9728e-05, scale: 262144.0000 | grad_norm: 1.3055\cb1 \
\cb3 2023-07-12 04:13:01 | Iter: 12800 | loss: 2.1493 | lr: 9.9718e-05, scale: 262144.0000 | grad_norm: 1.4639\cb1 \
\cb3 2023-07-12 04:15:14 | Iter: 12900 | loss: 2.1327 | lr: 9.9708e-05, scale: 262144.0000 | grad_norm: 1.3364\cb1 \
\cb3 Gradient overflow, change scale from 524288.000000 to 262144.000000\cb1 \
\cb3 2023-07-12 04:17:28 | Iter: 13000 | loss: 2.1367 | lr: 9.9698e-05, scale: 262144.0000 | grad_norm: 1.2732\cb1 \
\cb3 start valid!\cb1 \
\cb3 2023-07-12 04:17:45 | Iter: 13000 | valid loss: 2.0690\cb1 \
\cb3 saving status into: /data/checkpoints/checkpoint-13000.success\cb1 \
\cb3 Saving checkpoint at 13000 step.\cb1 \
\cb3 2023-07-12 04:20:11 | Iter: 13100 | loss: 2.1165 | lr: 9.9688e-05, scale: 262144.0000 | grad_norm: 1.2743\cb1 \
\cb3 Gradient overflow, change scale from 262144.000000 to 131072.000000\cb1 \
\cb3 2023-07-12 04:22:22 | Iter: 13200 | loss: 2.1104 | lr: 9.9678e-05, scale: 131072.0000 | grad_norm: 1.2282\cb1 \
\cb3 2023-07-12 04:24:38 | Iter: 13300 | loss: 2.1160 | lr: 9.9668e-05, scale: 131072.0000 | grad_norm: 1.1962\cb1 \
\cb3 2023-07-12 04:26:54 | Iter: 13400 | loss: 2.0993 | lr: 9.9658e-05, scale: 131072.0000 | grad_norm: 1.3687\cb1 \
\cb3 2023-07-12 04:29:09 | Iter: 13500 | loss: 2.0987 | lr: 9.9648e-05, scale: 131072.0000 | grad_norm: 1.2543\cb1 \
\cb3 start valid!\cb1 \
\cb3 2023-07-12 04:29:25 | Iter: 13500 | valid loss: 2.0320\cb1 \
\cb3 saving status into: /data/checkpoints/checkpoint-13500.success\cb1 \
\cb3 Saving checkpoint at 13500 step.\cb1 \
\cb3 2023-07-12 04:31:58 | Iter: 13600 | loss: 2.0935 | lr: 9.9638e-05, scale: 131072.0000 | grad_norm: 1.3369\cb1 \
\cb3 2023-07-12 04:34:12 | Iter: 13700 | loss: 2.0920 | lr: 9.9628e-05, scale: 131072.0000 | grad_norm: 1.3401\cb1 \
\cb3 2023-07-12 04:36:24 | Iter: 13800 | loss: 2.0714 | lr: 9.9617e-05, scale: 131072.0000 | grad_norm: 1.2679\cb1 \
\cb3 2023-07-12 04:38:41 | Iter: 13900 | loss: 2.0751 | lr: 9.9607e-05, scale: 131072.0000 | grad_norm: 1.2486\cb1 \
\cb3 2023-07-12 04:40:56 | Iter: 14000 | loss: 2.0563 | lr: 9.9597e-05, scale: 131072.0000 | grad_norm: 1.3502\cb1 \
\cb3 start valid!\cb1 \
\cb3 2023-07-12 04:41:10 | Iter: 14000 | valid loss: 2.0063\cb1 \
\cb3 saving status into: /data/checkpoints/checkpoint-14000.success\cb1 \
\cb3 Saving checkpoint at 14000 step.\cb1 \
\cb3 2023-07-12 04:43:37 | Iter: 14100 | loss: 2.0616 | lr: 9.9587e-05, scale: 131072.0000 | grad_norm: 1.2750\cb1 \
\cb3 2023-07-12 04:45:51 | Iter: 14200 | loss: 2.0514 | lr: 9.9577e-05, scale: 262144.0000 | grad_norm: 1.3072\cb1 \
\cb3 2023-07-12 04:48:06 | Iter: 14300 | loss: 2.0394 | lr: 9.9567e-05, scale: 262144.0000 | grad_norm: 1.3791\cb1 \
\cb3 2023-07-12 04:50:19 | Iter: 14400 | loss: 2.0350 | lr: 9.9557e-05, scale: 262144.0000 | grad_norm: 1.2667\cb1 \
\cb3 2023-07-12 04:52:33 | Iter: 14500 | loss: 2.0243 | lr: 9.9547e-05, scale: 262144.0000 | grad_norm: 1.2564\cb1 \
\cb3 start valid!\cb1 \
\cb3 2023-07-12 04:52:49 | Iter: 14500 | valid loss: 1.9608\cb1 \
\cb3 saving status into: /data/checkpoints/checkpoint-14500.success\cb1 \
\cb3 Saving checkpoint at 14500 step.\cb1 \
\cb3 2023-07-12 04:55:15 | Iter: 14600 | loss: 2.0287 | lr: 9.9537e-05, scale: 262144.0000 | grad_norm: 1.2132\cb1 \
\cb3 2023-07-12 04:57:28 | Iter: 14700 | loss: 2.0302 | lr: 9.9527e-05, scale: 262144.0000 | grad_norm: 1.3002\cb1 \
\cb3 2023-07-12 04:59:42 | Iter: 14800 | loss: 2.0133 | lr: 9.9516e-05, scale: 262144.0000 | grad_norm: 1.2096\cb1 \
\cb3 2023-07-12 05:01:57 | Iter: 14900 | loss: 2.0180 | lr: 9.9506e-05, scale: 262144.0000 | grad_norm: 1.2566\cb1 \
\cb3 2023-07-12 05:04:11 | Iter: 15000 | loss: 2.0088 | lr: 9.9496e-05, scale: 262144.0000 | grad_norm: 1.2503\cb1 \
\cb3 start valid!\cb1 \
\cb3 2023-07-12 05:04:25 | Iter: 15000 | valid loss: 1.9470\cb1 \
\cb3 saving status into: /data/checkpoints/checkpoint-15000.success\cb1 \
\cb3 Saving checkpoint at 15000 step.\cb1 \
\cb3 2023-07-12 05:06:51 | Iter: 15100 | loss: 2.0021 | lr: 9.9486e-05, scale: 262144.0000 | grad_norm: 1.3151\cb1 \
\cb3 2023-07-12 05:09:06 | Iter: 15200 | loss: 2.0043 | lr: 9.9476e-05, scale: 262144.0000 | grad_norm: 1.3385\cb1 \
\cb3 Gradient overflow, change scale from 524288.000000 to 262144.000000\cb1 \
\cb3 2023-07-12 05:11:22 | Iter: 15300 | loss: 2.0003 | lr: 9.9466e-05, scale: 262144.0000 | grad_norm: 1.3055\cb1 \
\cb3 2023-07-12 05:13:40 | Iter: 15400 | loss: 1.9873 | lr: 9.9456e-05, scale: 262144.0000 | grad_norm: 1.2376\cb1 \
\cb3 2023-07-12 05:15:56 | Iter: 15500 | loss: 1.9828 | lr: 9.9446e-05, scale: 262144.0000 | grad_norm: 1.2153\cb1 \
\cb3 start valid!\cb1 \
\cb3 2023-07-12 05:16:11 | Iter: 15500 | valid loss: 1.9212\cb1 \
\cb3 saving status into: /data/checkpoints/checkpoint-15500.success\cb1 \
\cb3 Saving checkpoint at 15500 step.\cb1 \
\cb3 2023-07-12 05:18:40 | Iter: 15600 | loss: 1.9831 | lr: 9.9436e-05, scale: 262144.0000 | grad_norm: 1.2189\cb1 \
\cb3 2023-07-12 05:20:57 | Iter: 15700 | loss: 1.9723 | lr: 9.9426e-05, scale: 262144.0000 | grad_norm: 1.2366\cb1 \
\cb3 2023-07-12 05:23:12 | Iter: 15800 | loss: 1.9734 | lr: 9.9416e-05, scale: 262144.0000 | grad_norm: 1.2233\cb1 \
\cb3 2023-07-12 05:25:28 | Iter: 15900 | loss: 1.9701 | lr: 9.9405e-05, scale: 262144.0000 | grad_norm: 1.2910\cb1 \
\cb3 2023-07-12 05:27:43 | Iter: 16000 | loss: 1.9560 | lr: 9.9395e-05, scale: 262144.0000 | grad_norm: 1.1602\cb1 \
\cb3 start valid!\cb1 \
\cb3 2023-07-12 05:27:58 | Iter: 16000 | valid loss: 1.8991\cb1 \
\cb3 saving status into: /data/checkpoints/checkpoint-16000.success\cb1 \
\cb3 Saving checkpoint at 16000 step.\cb1 \
\cb3 2023-07-12 05:30:25 | Iter: 16100 | loss: 1.9538 | lr: 9.9385e-05, scale: 262144.0000 | grad_norm: 1.2325\cb1 \
\cb3 2023-07-12 05:32:40 | Iter: 16200 | loss: 1.9537 | lr: 9.9375e-05, scale: 262144.0000 | grad_norm: 1.2525\cb1 \
\cb3 Gradient overflow, change scale from 524288.000000 to 262144.000000\cb1 \
\cb3 2023-07-12 05:34:53 | Iter: 16300 | loss: 1.9513 | lr: 9.9365e-05, scale: 262144.0000 | grad_norm: 1.3127\cb1 \
\cb3 2023-07-12 05:37:10 | Iter: 16400 | loss: 1.9485 | lr: 9.9355e-05, scale: 262144.0000 | grad_norm: 1.1455\cb1 \
\cb3 2023-07-12 05:39:23 | Iter: 16500 | loss: 1.9478 | lr: 9.9345e-05, scale: 262144.0000 | grad_norm: 1.1911\cb1 \
\cb3 start valid!\cb1 \
\cb3 2023-07-12 05:39:40 | Iter: 16500 | valid loss: 1.8815\cb1 \
\cb3 saving status into: /data/checkpoints/checkpoint-16500.success\cb1 \
\cb3 Saving checkpoint at 16500 step.\cb1 \
\cb3 2023-07-12 05:42:05 | Iter: 16600 | loss: 1.9369 | lr: 9.9335e-05, scale: 262144.0000 | grad_norm: 1.1960\cb1 \
\cb3 2023-07-12 05:44:19 | Iter: 16700 | loss: 1.9311 | lr: 9.9325e-05, scale: 262144.0000 | grad_norm: 1.2010\cb1 \
\cb3 2023-07-12 05:46:34 | Iter: 16800 | loss: 1.9300 | lr: 9.9315e-05, scale: 262144.0000 | grad_norm: 1.1805\cb1 \
\cb3 2023-07-12 05:48:50 | Iter: 16900 | loss: 1.9266 | lr: 9.9305e-05, scale: 262144.0000 | grad_norm: 1.1894\cb1 \
\cb3 2023-07-12 05:51:05 | Iter: 17000 | loss: 1.9252 | lr: 9.9294e-05, scale: 262144.0000 | grad_norm: 1.1656\cb1 \
\cb3 start valid!\cb1 \
\cb3 2023-07-12 05:51:20 | Iter: 17000 | valid loss: 1.8646\cb1 \
\cb3 saving status into: /data/checkpoints/checkpoint-17000.success\cb1 \
\cb3 Saving checkpoint at 17000 step.\cb1 \
\cb3 2023-07-12 05:53:47 | Iter: 17100 | loss: 1.9178 | lr: 9.9284e-05, scale: 262144.0000 | grad_norm: 1.2594\cb1 \
\cb3 2023-07-12 05:56:01 | Iter: 17200 | loss: 1.9145 | lr: 9.9274e-05, scale: 262144.0000 | grad_norm: 1.3713\cb1 \
\cb3 Gradient overflow, change scale from 524288.000000 to 262144.000000\cb1 \
\cb3 2023-07-12 05:58:14 | Iter: 17300 | loss: 1.9102 | lr: 9.9264e-05, scale: 262144.0000 | grad_norm: 1.2107\cb1 \
\cb3 2023-07-12 06:00:29 | Iter: 17400 | loss: 1.9073 | lr: 9.9254e-05, scale: 262144.0000 | grad_norm: 1.1845\cb1 \
\cb3 2023-07-12 06:02:47 | Iter: 17500 | loss: 1.9023 | lr: 9.9244e-05, scale: 262144.0000 | grad_norm: 1.2696\cb1 \
\cb3 start valid!\cb1 \
\cb3 2023-07-12 06:03:02 | Iter: 17500 | valid loss: 1.8429\cb1 \
\cb3 saving status into: /data/checkpoints/checkpoint-17500.success\cb1 \
\cb3 Saving checkpoint at 17500 step.\cb1 \
\cb3 2023-07-12 06:05:29 | Iter: 17600 | loss: 1.9016 | lr: 9.9234e-05, scale: 262144.0000 | grad_norm: 1.1666\cb1 \
\cb3 2023-07-12 06:07:44 | Iter: 17700 | loss: 1.9018 | lr: 9.9224e-05, scale: 262144.0000 | grad_norm: 1.2377\cb1 \
\cb3 2023-07-12 06:09:57 | Iter: 17800 | loss: 1.8929 | lr: 9.9214e-05, scale: 262144.0000 | grad_norm: 1.2420\cb1 \
\cb3 2023-07-12 06:12:12 | Iter: 17900 | loss: 1.8926 | lr: 9.9204e-05, scale: 262144.0000 | grad_norm: 1.1482\cb1 \
\cb3 2023-07-12 06:14:28 | Iter: 18000 | loss: 1.8893 | lr: 9.9194e-05, scale: 262144.0000 | grad_norm: 1.1804\cb1 \
\cb3 start valid!\cb1 \
\cb3 2023-07-12 06:14:46 | Iter: 18000 | valid loss: 1.8265\cb1 \
\cb3 saving status into: /data/checkpoints/checkpoint-18000.success\cb1 \
\cb3 Saving checkpoint at 18000 step.\cb1 \
\cb3 2023-07-12 06:17:13 | Iter: 18100 | loss: 1.8885 | lr: 9.9183e-05, scale: 262144.0000 | grad_norm: 1.1777\cb1 \
\cb3 2023-07-12 06:19:27 | Iter: 18200 | loss: 1.8855 | lr: 9.9173e-05, scale: 262144.0000 | grad_norm: 1.1885\cb1 \
\cb3 2023-07-12 06:21:44 | Iter: 18300 | loss: 1.8794 | lr: 9.9163e-05, scale: 262144.0000 | grad_norm: 1.1179\cb1 \
\cb3 Gradient overflow, change scale from 524288.000000 to 262144.000000\cb1 \
\cb3 2023-07-12 06:23:58 | Iter: 18400 | loss: 1.8754 | lr: 9.9153e-05, scale: 262144.0000 | grad_norm: 1.1594\cb1 \
\cb3 2023-07-12 06:26:12 | Iter: 18500 | loss: 1.8714 | lr: 9.9143e-05, scale: 262144.0000 | grad_norm: 1.1618\cb1 \
\cb3 start valid!\cb1 \
\cb3 2023-07-12 06:26:29 | Iter: 18500 | valid loss: 1.8258\cb1 \
\cb3 saving status into: /data/checkpoints/checkpoint-18500.success\cb1 \
\cb3 Saving checkpoint at 18500 step.\cb1 \
\cb3 2023-07-12 06:28:54 | Iter: 18600 | loss: 1.8746 | lr: 9.9133e-05, scale: 262144.0000 | grad_norm: 1.1605\cb1 \
\cb3 2023-07-12 06:31:09 | Iter: 18700 | loss: 1.8723 | lr: 9.9123e-05, scale: 262144.0000 | grad_norm: 1.2322\cb1 \
\cb3 2023-07-12 06:33:24 | Iter: 18800 | loss: 1.8639 | lr: 9.9113e-05, scale: 262144.0000 | grad_norm: 1.3529\cb1 \
\cb3 2023-07-12 06:35:39 | Iter: 18900 | loss: 1.8585 | lr: 9.9103e-05, scale: 262144.0000 | grad_norm: 1.2089\cb1 \
\cb3 2023-07-12 06:37:53 | Iter: 19000 | loss: 1.8680 | lr: 9.9093e-05, scale: 262144.0000 | grad_norm: 1.1833\cb1 \
\cb3 start valid!\cb1 \
\cb3 2023-07-12 06:38:08 | Iter: 19000 | valid loss: 1.8119\cb1 \
\cb3 saving status into: /data/checkpoints/checkpoint-19000.success\cb1 \
\cb3 Saving checkpoint at 19000 step.\cb1 \
\cb3 2023-07-12 06:40:36 | Iter: 19100 | loss: 1.8599 | lr: 9.9083e-05, scale: 262144.0000 | grad_norm: 1.1672\cb1 \
\cb3 2023-07-12 06:42:51 | Iter: 19200 | loss: 1.8494 | lr: 9.9072e-05, scale: 262144.0000 | grad_norm: 1.1184\cb1 \
\cb3 2023-07-12 06:45:05 | Iter: 19300 | loss: 1.8541 | lr: 9.9062e-05, scale: 262144.0000 | grad_norm: 1.1749\cb1 \
\cb3 Gradient overflow, change scale from 524288.000000 to 262144.000000\cb1 \
\cb3 2023-07-12 06:47:20 | Iter: 19400 | loss: 1.8511 | lr: 9.9052e-05, scale: 262144.0000 | grad_norm: 1.1789\cb1 \
\cb3 2023-07-12 06:49:34 | Iter: 19500 | loss: 1.8457 | lr: 9.9042e-05, scale: 262144.0000 | grad_norm: 1.2273\cb1 \
\cb3 start valid!\cb1 \
\cb3 2023-07-12 06:49:50 | Iter: 19500 | valid loss: 1.7895\cb1 \
\cb3 saving status into: /data/checkpoints/checkpoint-19500.success\cb1 \
\cb3 Saving checkpoint at 19500 step.\cb1 \
\cb3 2023-07-12 06:52:16 | Iter: 19600 | loss: 1.8425 | lr: 9.9032e-05, scale: 262144.0000 | grad_norm: 1.1707\cb1 \
\cb3 2023-07-12 06:54:30 | Iter: 19700 | loss: 1.8430 | lr: 9.9022e-05, scale: 262144.0000 | grad_norm: 1.1852\cb1 \
\cb3 2023-07-12 06:56:44 | Iter: 19800 | loss: 1.8353 | lr: 9.9012e-05, scale: 262144.0000 | grad_norm: 1.2418\cb1 \
\cb3 2023-07-12 06:58:57 | Iter: 19900 | loss: 1.8325 | lr: 9.9002e-05, scale: 262144.0000 | grad_norm: 1.2671\cb1 \
\cb3 2023-07-12 07:01:13 | Iter: 20000 | loss: 1.8360 | lr: 9.8992e-05, scale: 262144.0000 | grad_norm: 1.1848\cb1 \
\cb3 start valid!\cb1 \
\cb3 2023-07-12 07:01:28 | Iter: 20000 | valid loss: 1.7694\cb1 \
\cb3 saving status into: /data/checkpoints/checkpoint-20000.success\cb1 \
\cb3 Saving checkpoint at 20000 step.\cb1 \
\cb3 2023-07-12 07:03:55 | Iter: 20100 | loss: 1.8330 | lr: 9.8982e-05, scale: 262144.0000 | grad_norm: 1.2815\cb1 \
\cb3 2023-07-12 07:06:09 | Iter: 20200 | loss: 1.8236 | lr: 9.8972e-05, scale: 262144.0000 | grad_norm: 1.1922\cb1 \
\cb3 2023-07-12 07:08:24 | Iter: 20300 | loss: 1.8202 | lr: 9.8961e-05, scale: 262144.0000 | grad_norm: 1.1511\cb1 \
\cb3 Gradient overflow, change scale from 524288.000000 to 262144.000000\cb1 \
\cb3 2023-07-12 07:10:38 | Iter: 20400 | loss: 1.8214 | lr: 9.8951e-05, scale: 262144.0000 | grad_norm: 1.1857\cb1 \
\cb3 2023-07-12 07:12:52 | Iter: 20500 | loss: 1.8237 | lr: 9.8941e-05, scale: 262144.0000 | grad_norm: 1.2330\cb1 \
\cb3 start valid!\cb1 \
\cb3 2023-07-12 07:13:07 | Iter: 20500 | valid loss: 1.7741\cb1 \
\cb3 saving status into: /data/checkpoints/checkpoint-20500.success\cb1 \
\cb3 Saving checkpoint at 20500 step.\cb1 \
\cb3 2023-07-12 07:15:33 | Iter: 20600 | loss: 1.8134 | lr: 9.8931e-05, scale: 262144.0000 | grad_norm: 1.1611\cb1 \
\cb3 2023-07-12 07:17:48 | Iter: 20700 | loss: 1.8186 | lr: 9.8921e-05, scale: 262144.0000 | grad_norm: 1.1582\cb1 \
\cb3 2023-07-12 07:20:01 | Iter: 20800 | loss: 1.8055 | lr: 9.8911e-05, scale: 262144.0000 | grad_norm: 1.1212\cb1 \
\cb3 2023-07-12 07:22:16 | Iter: 20900 | loss: 1.8120 | lr: 9.8901e-05, scale: 262144.0000 | grad_norm: 1.1097\cb1 \
\cb3 2023-07-12 07:24:30 | Iter: 21000 | loss: 1.8141 | lr: 9.8891e-05, scale: 262144.0000 | grad_norm: 1.1937\cb1 \
\cb3 start valid!\cb1 \
\cb3 2023-07-12 07:24:46 | Iter: 21000 | valid loss: 1.7575\cb1 \
\cb3 saving status into: /data/checkpoints/checkpoint-21000.success\cb1 \
\cb3 Saving checkpoint at 21000 step.\cb1 \
\cb3 2023-07-12 07:27:13 | Iter: 21100 | loss: 1.8049 | lr: 9.8881e-05, scale: 262144.0000 | grad_norm: 1.1007\cb1 \
\cb3 2023-07-12 07:29:27 | Iter: 21200 | loss: 1.8071 | lr: 9.8871e-05, scale: 262144.0000 | grad_norm: 1.0909\cb1 \
\cb3 2023-07-12 07:31:43 | Iter: 21300 | loss: 1.8078 | lr: 9.8861e-05, scale: 262144.0000 | grad_norm: 1.1712\cb1 \
\cb3 2023-07-12 07:34:00 | Iter: 21400 | loss: 1.7948 | lr: 9.8850e-05, scale: 262144.0000 | grad_norm: 1.1649\cb1 \
\cb3 Gradient overflow, change scale from 524288.000000 to 262144.000000\cb1 \
\cb3 2023-07-12 07:36:17 | Iter: 21500 | loss: 1.7934 | lr: 9.8840e-05, scale: 262144.0000 | grad_norm: 1.1276\cb1 \
\cb3 start valid!\cb1 \
\cb3 2023-07-12 07:36:33 | Iter: 21500 | valid loss: 1.7407\cb1 \
\cb3 saving status into: /data/checkpoints/checkpoint-21500.success\cb1 \
\cb3 Saving checkpoint at 21500 step.\cb1 \
\cb3 2023-07-12 07:38:58 | Iter: 21600 | loss: 1.7958 | lr: 9.8830e-05, scale: 262144.0000 | grad_norm: 1.1065\cb1 \
\cb3 2023-07-12 07:41:14 | Iter: 21700 | loss: 1.7959 | lr: 9.8820e-05, scale: 262144.0000 | grad_norm: 1.1969\cb1 \
\cb3 2023-07-12 07:43:28 | Iter: 21800 | loss: 1.7900 | lr: 9.8810e-05, scale: 262144.0000 | grad_norm: 1.1590\cb1 \
\cb3 2023-07-12 07:45:42 | Iter: 21900 | loss: 1.7861 | lr: 9.8800e-05, scale: 262144.0000 | grad_norm: 1.1418\cb1 \
\cb3 2023-07-12 07:47:56 | Iter: 22000 | loss: 1.7861 | lr: 9.8790e-05, scale: 262144.0000 | grad_norm: 1.1151\cb1 \
\cb3 start valid!\cb1 \
\cb3 2023-07-12 07:48:11 | Iter: 22000 | valid loss: 1.7256\cb1 \
\cb3 saving status into: /data/checkpoints/checkpoint-22000.success\cb1 \
\cb3 Saving checkpoint at 22000 step.\cb1 \
\cb3 2023-07-12 07:50:38 | Iter: 22100 | loss: 1.7813 | lr: 9.8780e-05, scale: 262144.0000 | grad_norm: 1.1600\cb1 \
\cb3 2023-07-12 07:52:51 | Iter: 22200 | loss: 1.7897 | lr: 9.8770e-05, scale: 262144.0000 | grad_norm: 1.1633\cb1 \
\cb3 2023-07-12 07:55:06 | Iter: 22300 | loss: 1.7788 | lr: 9.8760e-05, scale: 262144.0000 | grad_norm: 1.1114\cb1 \
\cb3 2023-07-12 07:57:20 | Iter: 22400 | loss: 1.7769 | lr: 9.8749e-05, scale: 262144.0000 | grad_norm: 1.0987\cb1 \
\cb3 Gradient overflow, change scale from 524288.000000 to 262144.000000\cb1 \
\cb3 2023-07-12 07:59:34 | Iter: 22500 | loss: 1.7703 | lr: 9.8739e-05, scale: 262144.0000 | grad_norm: 1.1504\cb1 \
\cb3 start valid!\cb1 \
\cb3 2023-07-12 07:59:49 | Iter: 22500 | valid loss: 1.7221\cb1 \
\cb3 saving status into: /data/checkpoints/checkpoint-22500.success\cb1 \
\cb3 Saving checkpoint at 22500 step.\cb1 \
\cb3 Gradient overflow, change scale from 262144.000000 to 131072.000000\cb1 \
\cb3 2023-07-12 08:02:15 | Iter: 22600 | loss: 1.7686 | lr: 9.8729e-05, scale: 131072.0000 | grad_norm: 1.1413\cb1 \
\cb3 2023-07-12 08:04:28 | Iter: 22700 | loss: 1.7701 | lr: 9.8719e-05, scale: 131072.0000 | grad_norm: 1.1522\cb1 \
\cb3 2023-07-12 08:06:44 | Iter: 22800 | loss: 1.7713 | lr: 9.8709e-05, scale: 131072.0000 | grad_norm: 1.1108\cb1 \
\cb3 2023-07-12 08:08:58 | Iter: 22900 | loss: 1.7658 | lr: 9.8699e-05, scale: 131072.0000 | grad_norm: 1.3028\cb1 \
\cb3 2023-07-12 08:11:10 | Iter: 23000 | loss: 1.7627 | lr: 9.8689e-05, scale: 131072.0000 | grad_norm: 1.1632\cb1 \
\cb3 start valid!\cb1 \
\cb3 2023-07-12 08:11:26 | Iter: 23000 | valid loss: 1.7116\cb1 \
\cb3 saving status into: /data/checkpoints/checkpoint-23000.success\cb1 \
\cb3 Saving checkpoint at 23000 step.\cb1 \
\cb3 2023-07-12 08:13:52 | Iter: 23100 | loss: 1.7605 | lr: 9.8679e-05, scale: 131072.0000 | grad_norm: 1.1687\cb1 \
\cb3 2023-07-12 08:16:08 | Iter: 23200 | loss: 1.7657 | lr: 9.8669e-05, scale: 131072.0000 | grad_norm: 1.1252\cb1 \
\cb3 2023-07-12 08:18:20 | Iter: 23300 | loss: 1.7581 | lr: 9.8659e-05, scale: 131072.0000 | grad_norm: 1.1362\cb1 \
\cb3 2023-07-12 08:20:33 | Iter: 23400 | loss: 1.7521 | lr: 9.8649e-05, scale: 131072.0000 | grad_norm: 1.1099\cb1 \
\cb3 2023-07-12 08:22:49 | Iter: 23500 | loss: 1.7561 | lr: 9.8639e-05, scale: 131072.0000 | grad_norm: 1.1027\cb1 \
\cb3 start valid!\cb1 \
\cb3 2023-07-12 08:23:04 | Iter: 23500 | valid loss: 1.6980\cb1 \
\cb3 saving status into: /data/checkpoints/checkpoint-23500.success\cb1 \
\cb3 Saving checkpoint at 23500 step.\cb1 \
\cb3 2023-07-12 08:25:30 | Iter: 23600 | loss: 1.7441 | lr: 9.8628e-05, scale: 262144.0000 | grad_norm: 1.1097\cb1 \
\cb3 2023-07-12 08:27:45 | Iter: 23700 | loss: 1.7505 | lr: 9.8618e-05, scale: 262144.0000 | grad_norm: 1.1251\cb1 \
\cb3 2023-07-12 08:29:59 | Iter: 23800 | loss: 1.7504 | lr: 9.8608e-05, scale: 262144.0000 | grad_norm: 1.1148\cb1 \
\cb3 2023-07-12 08:32:17 | Iter: 23900 | loss: 1.7437 | lr: 9.8598e-05, scale: 262144.0000 | grad_norm: 1.1314\cb1 \
\cb3 2023-07-12 08:34:32 | Iter: 24000 | loss: 1.7477 | lr: 9.8588e-05, scale: 262144.0000 | grad_norm: 1.0884\cb1 \
\cb3 start valid!\cb1 \
\cb3 2023-07-12 08:34:47 | Iter: 24000 | valid loss: 1.6917\cb1 \
\cb3 saving status into: /data/checkpoints/checkpoint-24000.success\cb1 \
\cb3 Saving checkpoint at 24000 step.\cb1 \
\cb3 2023-07-12 08:37:15 | Iter: 24100 | loss: 1.7409 | lr: 9.8578e-05, scale: 262144.0000 | grad_norm: 1.1504\cb1 \
\cb3 2023-07-12 08:39:28 | Iter: 24200 | loss: 1.7500 | lr: 9.8568e-05, scale: 262144.0000 | grad_norm: 1.1184\cb1 \
\cb3 2023-07-12 08:41:45 | Iter: 24300 | loss: 1.7438 | lr: 9.8558e-05, scale: 262144.0000 | grad_norm: 1.3260\cb1 \
\cb3 2023-07-12 08:44:00 | Iter: 24400 | loss: 1.7475 | lr: 9.8548e-05, scale: 262144.0000 | grad_norm: 1.1450\cb1 \
\cb3 2023-07-12 08:46:15 | Iter: 24500 | loss: 1.7414 | lr: 9.8538e-05, scale: 262144.0000 | grad_norm: 1.2055\cb1 \
\cb3 start valid!\cb1 \
\cb3 2023-07-12 08:46:31 | Iter: 24500 | valid loss: 1.6975\cb1 \
\cb3 saving status into: /data/checkpoints/checkpoint-24500.success\cb1 \
\cb3 Saving checkpoint at 24500 step.\cb1 \
\cb3 2023-07-12 08:48:58 | Iter: 24600 | loss: 1.7347 | lr: 9.8527e-05, scale: 524288.0000 | grad_norm: 0.7917\cb1 \
\cb3 Gradient overflow, change scale from 524288.000000 to 262144.000000\cb1 \
\cb3 2023-07-12 08:51:13 | Iter: 24700 | loss: 1.7307 | lr: 9.8517e-05, scale: 262144.0000 | grad_norm: 1.1958\cb1 \
\cb3 2023-07-12 08:53:27 | Iter: 24800 | loss: 1.7400 | lr: 9.8507e-05, scale: 262144.0000 | grad_norm: 1.1594\cb1 \
\cb3 2023-07-12 08:55:40 | Iter: 24900 | loss: 1.7344 | lr: 9.8497e-05, scale: 262144.0000 | grad_norm: 1.3019\cb1 \
\cb3 2023-07-12 08:57:59 | Iter: 25000 | loss: 1.7308 | lr: 9.8487e-05, scale: 262144.0000 | grad_norm: 1.1734\cb1 \
\cb3 start valid!\cb1 \
\cb3 2023-07-12 08:58:14 | Iter: 25000 | valid loss: 1.6875\cb1 \
\cb3 saving status into: /data/checkpoints/checkpoint-25000.success\cb1 \
\cb3 Saving checkpoint at 25000 step.\cb1 \
\cb3 2023-07-12 09:00:45 | Iter: 25100 | loss: 1.7325 | lr: 9.8477e-05, scale: 262144.0000 | grad_norm: 1.0885\cb1 \
\cb3 2023-07-12 09:03:00 | Iter: 25200 | loss: 1.7229 | lr: 9.8467e-05, scale: 262144.0000 | grad_norm: 1.1488\cb1 \
\cb3 2023-07-12 09:05:15 | Iter: 25300 | loss: 1.7150 | lr: 9.8457e-05, scale: 262144.0000 | grad_norm: 1.1331\cb1 \
\cb3 2023-07-12 09:07:28 | Iter: 25400 | loss: 1.7232 | lr: 9.8447e-05, scale: 262144.0000 | grad_norm: 1.0924\cb1 \
\cb3 2023-07-12 09:09:43 | Iter: 25500 | loss: 1.7326 | lr: 9.8437e-05, scale: 262144.0000 | grad_norm: 1.1269\cb1 \
\cb3 start valid!\cb1 \
\cb3 2023-07-12 09:09:59 | Iter: 25500 | valid loss: 1.6830\cb1 \
\cb3 saving status into: /data/checkpoints/checkpoint-25500.success\cb1 \
\cb3 Saving checkpoint at 25500 step.\cb1 \
\cb3 2023-07-12 09:12:26 | Iter: 25600 | loss: 1.7153 | lr: 9.8427e-05, scale: 262144.0000 | grad_norm: 1.1633\cb1 \
\cb3 Gradient overflow, change scale from 524288.000000 to 262144.000000\cb1 \
\cb3 2023-07-12 09:14:40 | Iter: 25700 | loss: 1.7154 | lr: 9.8417e-05, scale: 262144.0000 | grad_norm: 1.1229\cb1 \
\cb3 2023-07-12 09:16:54 | Iter: 25800 | loss: 1.7203 | lr: 9.8406e-05, scale: 262144.0000 | grad_norm: 1.1062\cb1 \
\cb3 2023-07-12 09:19:09 | Iter: 25900 | loss: 1.7151 | lr: 9.8396e-05, scale: 262144.0000 | grad_norm: 1.0899\cb1 \
\cb3 2023-07-12 09:21:23 | Iter: 26000 | loss: 1.7150 | lr: 9.8386e-05, scale: 262144.0000 | grad_norm: 1.1518\cb1 \
\cb3 start valid!\cb1 \
\cb3 2023-07-12 09:21:40 | Iter: 26000 | valid loss: 1.6490\cb1 \
\cb3 saving status into: /data/checkpoints/checkpoint-26000.success\cb1 \
\cb3 Saving checkpoint at 26000 step.\cb1 \
\cb3 2023-07-12 09:24:07 | Iter: 26100 | loss: 1.7021 | lr: 9.8376e-05, scale: 262144.0000 | grad_norm: 1.1866\cb1 \
\cb3 2023-07-12 09:26:22 | Iter: 26200 | loss: 1.7069 | lr: 9.8366e-05, scale: 262144.0000 | grad_norm: 1.0989\cb1 \
\cb3 2023-07-12 09:28:40 | Iter: 26300 | loss: 1.7138 | lr: 9.8356e-05, scale: 262144.0000 | grad_norm: 1.1998\cb1 \
\cb3 2023-07-12 09:30:55 | Iter: 26400 | loss: 1.6977 | lr: 9.8346e-05, scale: 262144.0000 | grad_norm: 1.1330\cb1 \
\cb3 2023-07-12 09:33:11 | Iter: 26500 | loss: 1.7070 | lr: 9.8336e-05, scale: 262144.0000 | grad_norm: 1.0804\cb1 \
\cb3 start valid!\cb1 \
\cb3 2023-07-12 09:33:28 | Iter: 26500 | valid loss: 1.6364\cb1 \
\cb3 saving status into: /data/checkpoints/checkpoint-26500.success\cb1 \
\cb3 Saving checkpoint at 26500 step.\cb1 \
\cb3 2023-07-12 09:35:54 | Iter: 26600 | loss: 1.7030 | lr: 9.8326e-05, scale: 262144.0000 | grad_norm: 1.1107\cb1 \
\cb3 2023-07-12 09:38:09 | Iter: 26700 | loss: 1.6970 | lr: 9.8316e-05, scale: 524288.0000 | grad_norm: 1.1080\cb1 \
\cb3 Gradient overflow, change scale from 524288.000000 to 262144.000000\cb1 \
\cb3 2023-07-12 09:40:22 | Iter: 26800 | loss: 1.6880 | lr: 9.8306e-05, scale: 262144.0000 | grad_norm: 1.0921\cb1 \
\cb3 2023-07-12 09:42:40 | Iter: 26900 | loss: 1.7011 | lr: 9.8295e-05, scale: 262144.0000 | grad_norm: 1.1270\cb1 \
\cb3 2023-07-12 09:44:54 | Iter: 27000 | loss: 1.6961 | lr: 9.8285e-05, scale: 262144.0000 | grad_norm: 1.1126\cb1 \
\cb3 start valid!\cb1 \
\cb3 2023-07-12 09:45:11 | Iter: 27000 | valid loss: 1.6321\cb1 \
\cb3 saving status into: /data/checkpoints/checkpoint-27000.success\cb1 \
\cb3 Saving checkpoint at 27000 step.\cb1 \
\cb3 2023-07-12 09:47:42 | Iter: 27100 | loss: 1.6884 | lr: 9.8275e-05, scale: 262144.0000 | grad_norm: 1.1344\cb1 \
\cb3 2023-07-12 09:49:58 | Iter: 27200 | loss: 1.6887 | lr: 9.8265e-05, scale: 262144.0000 | grad_norm: 1.0768\cb1 \
\cb3 2023-07-12 09:52:12 | Iter: 27300 | loss: 1.6898 | lr: 9.8255e-05, scale: 262144.0000 | grad_norm: 1.2064\cb1 \
\cb3 Gradient overflow, change scale from 262144.000000 to 131072.000000\cb1 \
\cb3 2023-07-12 09:54:25 | Iter: 27400 | loss: 1.6889 | lr: 9.8245e-05, scale: 131072.0000 | grad_norm: 1.0294\cb1 \
\cb3 2023-07-12 09:56:41 | Iter: 27500 | loss: 1.6891 | lr: 9.8235e-05, scale: 131072.0000 | grad_norm: 1.1070\cb1 \
\cb3 start valid!\cb1 \
\cb3 2023-07-12 09:56:58 | Iter: 27500 | valid loss: 1.6188\cb1 \
\cb3 saving status into: /data/checkpoints/checkpoint-27500.success\cb1 \
\cb3 Saving checkpoint at 27500 step.\cb1 \
\cb3 2023-07-12 09:59:27 | Iter: 27600 | loss: 1.6869 | lr: 9.8225e-05, scale: 131072.0000 | grad_norm: 1.1025\cb1 \
\cb3 2023-07-12 10:01:42 | Iter: 27700 | loss: 1.6826 | lr: 9.8215e-05, scale: 131072.0000 | grad_norm: 1.1375\cb1 \
\cb3 2023-07-12 10:03:57 | Iter: 27800 | loss: 1.6821 | lr: 9.8205e-05, scale: 131072.0000 | grad_norm: 1.0572\cb1 \
\cb3 2023-07-12 10:06:11 | Iter: 27900 | loss: 1.6788 | lr: 9.8195e-05, scale: 131072.0000 | grad_norm: 1.1493\cb1 \
\cb3 2023-07-12 10:08:27 | Iter: 28000 | loss: 1.6754 | lr: 9.8184e-05, scale: 131072.0000 | grad_norm: 1.0752\cb1 \
\cb3 start valid!\cb1 \
\cb3 2023-07-12 10:08:44 | Iter: 28000 | valid loss: 1.6073\cb1 \
\cb3 saving status into: /data/checkpoints/checkpoint-28000.success\cb1 \
\cb3 Saving checkpoint at 28000 step.\cb1 \
\cb3 2023-07-12 10:11:11 | Iter: 28100 | loss: 1.6732 | lr: 9.8174e-05, scale: 131072.0000 | grad_norm: 1.0986\cb1 \
\cb3 2023-07-12 10:13:26 | Iter: 28200 | loss: 1.6765 | lr: 9.8164e-05, scale: 131072.0000 | grad_norm: 1.0891\cb1 \
\cb3 2023-07-12 10:15:42 | Iter: 28300 | loss: 1.6671 | lr: 9.8154e-05, scale: 131072.0000 | grad_norm: 1.0795\cb1 \
\cb3 2023-07-12 10:17:56 | Iter: 28400 | loss: 1.6791 | lr: 9.8144e-05, scale: 131072.0000 | grad_norm: 1.1433\cb1 \
\cb3 2023-07-12 10:20:12 | Iter: 28500 | loss: 1.6652 | lr: 9.8134e-05, scale: 262144.0000 | grad_norm: 1.0880\cb1 \
\cb3 start valid!\cb1 \
\cb3 2023-07-12 10:20:26 | Iter: 28500 | valid loss: 1.6019\cb1 \
\cb3 saving status into: /data/checkpoints/checkpoint-28500.success\cb1 \
\cb3 Saving checkpoint at 28500 step.\cb1 \
\cb3 2023-07-12 10:22:53 | Iter: 28600 | loss: 1.6667 | lr: 9.8124e-05, scale: 262144.0000 | grad_norm: 1.0788\cb1 \
\cb3 2023-07-12 10:25:08 | Iter: 28700 | loss: 1.6703 | lr: 9.8114e-05, scale: 262144.0000 | grad_norm: 1.1010\cb1 \
\cb3 2023-07-12 10:27:23 | Iter: 28800 | loss: 1.6704 | lr: 9.8104e-05, scale: 262144.0000 | grad_norm: 1.1334\cb1 \
\cb3 2023-07-12 10:29:39 | Iter: 28900 | loss: 1.6641 | lr: 9.8094e-05, scale: 262144.0000 | grad_norm: 1.1211\cb1 \
\cb3 2023-07-12 10:31:53 | Iter: 29000 | loss: 1.6680 | lr: 9.8083e-05, scale: 262144.0000 | grad_norm: 1.0843\cb1 \
\cb3 start valid!\cb1 \
\cb3 2023-07-12 10:32:08 | Iter: 29000 | valid loss: 1.6079\cb1 \
\cb3 saving status into: /data/checkpoints/checkpoint-29000.success\cb1 \
\cb3 Saving checkpoint at 29000 step.\cb1 \
\cb3 2023-07-12 10:34:36 | Iter: 29100 | loss: 1.6625 | lr: 9.8073e-05, scale: 262144.0000 | grad_norm: 1.0811\cb1 \
\cb3 2023-07-12 10:36:52 | Iter: 29200 | loss: 1.6615 | lr: 9.8063e-05, scale: 262144.0000 | grad_norm: 1.1099\cb1 \
\cb3 2023-07-12 10:39:07 | Iter: 29300 | loss: 1.6627 | lr: 9.8053e-05, scale: 262144.0000 | grad_norm: 1.1018\cb1 \
\cb3 2023-07-12 10:41:21 | Iter: 29400 | loss: 1.6567 | lr: 9.8043e-05, scale: 262144.0000 | grad_norm: 1.1015\cb1 \
\cb3 Gradient overflow, change scale from 524288.000000 to 262144.000000\cb1 \
\cb3 2023-07-12 10:43:37 | Iter: 29500 | loss: 1.6556 | lr: 9.8033e-05, scale: 262144.0000 | grad_norm: 1.1293\cb1 \
\cb3 start valid!\cb1 \
\cb3 2023-07-12 10:43:52 | Iter: 29500 | valid loss: 1.6128\cb1 \
\cb3 saving status into: /data/checkpoints/checkpoint-29500.success\cb1 \
\cb3 Saving checkpoint at 29500 step.\cb1 \
\cb3 2023-07-12 10:46:19 | Iter: 29600 | loss: 1.6570 | lr: 9.8023e-05, scale: 262144.0000 | grad_norm: 1.0875\cb1 \
\cb3 2023-07-12 10:48:35 | Iter: 29700 | loss: 1.6522 | lr: 9.8013e-05, scale: 262144.0000 | grad_norm: 1.0908\cb1 \
\cb3 2023-07-12 10:50:50 | Iter: 29800 | loss: 1.6535 | lr: 9.8003e-05, scale: 262144.0000 | grad_norm: 1.1126\cb1 \
\cb3 2023-07-12 10:53:04 | Iter: 29900 | loss: 1.6516 | lr: 9.7993e-05, scale: 262144.0000 | grad_norm: 1.1421\cb1 \
\cb3 2023-07-12 10:55:20 | Iter: 30000 | loss: 1.6463 | lr: 9.7983e-05, scale: 262144.0000 | grad_norm: 1.0611\cb1 \
\cb3 start valid!\cb1 \
\cb3 2023-07-12 10:55:36 | Iter: 30000 | valid loss: 1.5856\cb1 \
\cb3 saving status into: /data/checkpoints/checkpoint-30000.success\cb1 \
\cb3 Saving checkpoint at 30000 step.\cb1 \
\cb3 2023-07-12 10:58:02 | Iter: 30100 | loss: 1.6551 | lr: 9.7972e-05, scale: 262144.0000 | grad_norm: 1.1524\cb1 \
\cb3 2023-07-12 11:00:16 | Iter: 30200 | loss: 1.6486 | lr: 9.7962e-05, scale: 262144.0000 | grad_norm: 1.1030\cb1 \
\cb3 2023-07-12 11:02:29 | Iter: 30300 | loss: 1.6461 | lr: 9.7952e-05, scale: 262144.0000 | grad_norm: 1.0624\cb1 \
\cb3 2023-07-12 11:04:44 | Iter: 30400 | loss: 1.6417 | lr: 9.7942e-05, scale: 262144.0000 | grad_norm: 1.1408\cb1 \
\cb3 Gradient overflow, change scale from 524288.000000 to 262144.000000\cb1 \
\cb3 2023-07-12 11:06:58 | Iter: 30500 | loss: 1.6382 | lr: 9.7932e-05, scale: 262144.0000 | grad_norm: 1.0904\cb1 \
\cb3 start valid!\cb1 \
\cb3 2023-07-12 11:07:13 | Iter: 30500 | valid loss: 1.5738\cb1 \
\cb3 saving status into: /data/checkpoints/checkpoint-30500.success\cb1 \
\cb3 Saving checkpoint at 30500 step.\cb1 \
\cb3 2023-07-12 11:09:42 | Iter: 30600 | loss: 1.6364 | lr: 9.7922e-05, scale: 262144.0000 | grad_norm: 1.0941\cb1 \
\cb3 2023-07-12 11:11:57 | Iter: 30700 | loss: 1.6376 | lr: 9.7912e-05, scale: 262144.0000 | grad_norm: 1.0984\cb1 \
\cb3 2023-07-12 11:14:11 | Iter: 30800 | loss: 1.6424 | lr: 9.7902e-05, scale: 262144.0000 | grad_norm: 1.0687\cb1 \
\cb3 2023-07-12 11:16:26 | Iter: 30900 | loss: 1.6389 | lr: 9.7892e-05, scale: 262144.0000 | grad_norm: 1.0959\cb1 \
\cb3 2023-07-12 11:18:41 | Iter: 31000 | loss: 1.6389 | lr: 9.7882e-05, scale: 262144.0000 | grad_norm: 1.0767\cb1 \
\cb3 start valid!\cb1 \
\cb3 2023-07-12 11:18:56 | Iter: 31000 | valid loss: 1.5708\cb1 \
\cb3 saving status into: /data/checkpoints/checkpoint-31000.success\cb1 \
\cb3 Saving checkpoint at 31000 step.\cb1 \
\cb3 2023-07-12 11:21:23 | Iter: 31100 | loss: 1.6354 | lr: 9.7872e-05, scale: 262144.0000 | grad_norm: 1.0426\cb1 \
\cb3 2023-07-12 11:23:39 | Iter: 31200 | loss: 1.6295 | lr: 9.7861e-05, scale: 262144.0000 | grad_norm: 1.1113\cb1 \
\cb3 2023-07-12 11:25:52 | Iter: 31300 | loss: 1.6374 | lr: 9.7851e-05, scale: 262144.0000 | grad_norm: 1.0778\cb1 \
\cb3 2023-07-12 11:28:07 | Iter: 31400 | loss: 1.6365 | lr: 9.7841e-05, scale: 262144.0000 | grad_norm: 1.0846\cb1 \
\cb3 2023-07-12 11:30:21 | Iter: 31500 | loss: 1.6333 | lr: 9.7831e-05, scale: 524288.0000 | grad_norm: 0.8380\cb1 \
\cb3 start valid!\cb1 \
\cb3 2023-07-12 11:30:38 | Iter: 31500 | valid loss: 1.5784\cb1 \
\cb3 saving status into: /data/checkpoints/checkpoint-31500.success\cb1 \
\cb3 Saving checkpoint at 31500 step.\cb1 \
\cb3 Gradient overflow, change scale from 524288.000000 to 262144.000000\cb1 \
\cb3 2023-07-12 11:33:05 | Iter: 31600 | loss: 1.6286 | lr: 9.7821e-05, scale: 262144.0000 | grad_norm: 1.0866\cb1 \
\cb3 2023-07-12 11:35:22 | Iter: 31700 | loss: 1.6289 | lr: 9.7811e-05, scale: 262144.0000 | grad_norm: 1.0465\cb1 \
\cb3 2023-07-12 11:37:36 | Iter: 31800 | loss: 1.6233 | lr: 9.7801e-05, scale: 262144.0000 | grad_norm: 1.0877\cb1 \
\cb3 2023-07-12 11:39:50 | Iter: 31900 | loss: 1.6274 | lr: 9.7791e-05, scale: 262144.0000 | grad_norm: 1.0369\cb1 \
\cb3 2023-07-12 11:42:05 | Iter: 32000 | loss: 1.6259 | lr: 9.7781e-05, scale: 262144.0000 | grad_norm: 1.0915\cb1 \
\cb3 start valid!\cb1 \
\cb3 2023-07-12 11:42:21 | Iter: 32000 | valid loss: 1.5772\cb1 \
\cb3 saving status into: /data/checkpoints/checkpoint-32000.success\cb1 \
\cb3 Saving checkpoint at 32000 step.\cb1 \
\cb3 2023-07-12 11:44:49 | Iter: 32100 | loss: 1.6218 | lr: 9.7771e-05, scale: 262144.0000 | grad_norm: 1.0690\cb1 \
\cb3 2023-07-12 11:47:05 | Iter: 32200 | loss: 1.6211 | lr: 9.7761e-05, scale: 262144.0000 | grad_norm: 1.1117\cb1 \
\cb3 2023-07-12 11:49:19 | Iter: 32300 | loss: 1.6202 | lr: 9.7750e-05, scale: 262144.0000 | grad_norm: 1.0671\cb1 \
\cb3 2023-07-12 11:51:34 | Iter: 32400 | loss: 1.6201 | lr: 9.7740e-05, scale: 262144.0000 | grad_norm: 1.0878\cb1 \
\cb3 2023-07-12 11:53:49 | Iter: 32500 | loss: 1.6137 | lr: 9.7730e-05, scale: 262144.0000 | grad_norm: 1.0760\cb1 \
\cb3 start valid!\cb1 \
\cb3 2023-07-12 11:54:05 | Iter: 32500 | valid loss: 1.5659\cb1 \
\cb3 saving status into: /data/checkpoints/checkpoint-32500.success\cb1 \
\cb3 Saving checkpoint at 32500 step.\cb1 \
\cb3 2023-07-12 11:56:31 | Iter: 32600 | loss: 1.6159 | lr: 9.7720e-05, scale: 524288.0000 | grad_norm: 1.1183\cb1 \
\cb3 Gradient overflow, change scale from 524288.000000 to 262144.000000\cb1 \
\cb3 2023-07-12 11:58:49 | Iter: 32700 | loss: 1.6114 | lr: 9.7710e-05, scale: 262144.0000 | grad_norm: 1.1028\cb1 \
\cb3 2023-07-12 12:01:04 | Iter: 32800 | loss: 1.6112 | lr: 9.7700e-05, scale: 262144.0000 | grad_norm: 1.0592\cb1 \
\cb3 2023-07-12 12:03:17 | Iter: 32900 | loss: 1.6132 | lr: 9.7690e-05, scale: 262144.0000 | grad_norm: 1.0643\cb1 \
\cb3 2023-07-12 12:05:33 | Iter: 33000 | loss: 1.6161 | lr: 9.7680e-05, scale: 262144.0000 | grad_norm: 1.1465\cb1 \
\cb3 start valid!\cb1 \
\cb3 2023-07-12 12:05:51 | Iter: 33000 | valid loss: 1.5686\cb1 \
\cb3 saving status into: /data/checkpoints/checkpoint-33000.success\cb1 \
\cb3 Saving checkpoint at 33000 step.\cb1 \
\cb3 2023-07-12 12:08:16 | Iter: 33100 | loss: 1.6165 | lr: 9.7670e-05, scale: 262144.0000 | grad_norm: 1.0679\cb1 \
\cb3 2023-07-12 12:10:31 | Iter: 33200 | loss: 1.6111 | lr: 9.7660e-05, scale: 262144.0000 | grad_norm: 1.0981\cb1 \
\cb3 2023-07-12 12:12:48 | Iter: 33300 | loss: 1.6062 | lr: 9.7649e-05, scale: 262144.0000 | grad_norm: 1.0965\cb1 \
\cb3 2023-07-12 12:15:01 | Iter: 33400 | loss: 1.6053 | lr: 9.7639e-05, scale: 262144.0000 | grad_norm: 1.1222\cb1 \
\cb3 2023-07-12 12:17:14 | Iter: 33500 | loss: 1.6105 | lr: 9.7629e-05, scale: 262144.0000 | grad_norm: 1.0867\cb1 \
\cb3 start valid!\cb1 \
\cb3 2023-07-12 12:17:30 | Iter: 33500 | valid loss: 1.5545\cb1 \
\cb3 saving status into: /data/checkpoints/checkpoint-33500.success\cb1 \
\cb3 Saving checkpoint at 33500 step.\cb1 \
\cb3 2023-07-12 12:19:56 | Iter: 33600 | loss: 1.5998 | lr: 9.7619e-05, scale: 262144.0000 | grad_norm: 1.0757\cb1 \
\cb3 Gradient overflow, change scale from 524288.000000 to 262144.000000\cb1 \
\cb3 2023-07-12 12:22:12 | Iter: 33700 | loss: 1.5997 | lr: 9.7609e-05, scale: 262144.0000 | grad_norm: 1.0488\cb1 \
\cb3 2023-07-12 12:24:26 | Iter: 33800 | loss: 1.6073 | lr: 9.7599e-05, scale: 262144.0000 | grad_norm: 1.1045\cb1 \
\cb3 2023-07-12 12:26:43 | Iter: 33900 | loss: 1.6067 | lr: 9.7589e-05, scale: 262144.0000 | grad_norm: 1.0754\cb1 \
\cb3 2023-07-12 12:28:57 | Iter: 34000 | loss: 1.6012 | lr: 9.7579e-05, scale: 262144.0000 | grad_norm: 1.0707\cb1 \
\cb3 start valid!\cb1 \
\cb3 2023-07-12 12:29:13 | Iter: 34000 | valid loss: 1.5553\cb1 \
\cb3 saving status into: /data/checkpoints/checkpoint-34000.success\cb1 \
\cb3 Saving checkpoint at 34000 step.\cb1 \
\cb3 2023-07-12 12:31:41 | Iter: 34100 | loss: 1.6054 | lr: 9.7569e-05, scale: 262144.0000 | grad_norm: 1.0823\cb1 \
\cb3 2023-07-12 12:33:55 | Iter: 34200 | loss: 1.5968 | lr: 9.7559e-05, scale: 262144.0000 | grad_norm: 1.0646\cb1 \
\cb3 2023-07-12 12:36:10 | Iter: 34300 | loss: 1.5987 | lr: 9.7549e-05, scale: 262144.0000 | grad_norm: 1.1256\cb1 \
\cb3 2023-07-12 12:38:24 | Iter: 34400 | loss: 1.5948 | lr: 9.7538e-05, scale: 262144.0000 | grad_norm: 1.0258\cb1 \
\cb3 2023-07-12 12:40:41 | Iter: 34500 | loss: 1.6020 | lr: 9.7528e-05, scale: 262144.0000 | grad_norm: 1.1104\cb1 \
\cb3 start valid!\cb1 \
\cb3 2023-07-12 12:40:57 | Iter: 34500 | valid loss: 1.5387\cb1 \
\cb3 saving status into: /data/checkpoints/checkpoint-34500.success\cb1 \
\cb3 Saving checkpoint at 34500 step.\cb1 \
\cb3 2023-07-12 12:43:24 | Iter: 34600 | loss: 1.5957 | lr: 9.7518e-05, scale: 262144.0000 | grad_norm: 1.0856\cb1 \
\cb3 2023-07-12 12:45:41 | Iter: 34700 | loss: 1.5966 | lr: 9.7508e-05, scale: 524288.0000 | grad_norm: 1.0993\cb1 \
\cb3 Gradient overflow, change scale from 524288.000000 to 262144.000000\cb1 \
\cb3 2023-07-12 12:47:54 | Iter: 34800 | loss: 1.5921 | lr: 9.7498e-05, scale: 262144.0000 | grad_norm: 1.0629\cb1 \
\cb3 2023-07-12 12:50:06 | Iter: 34900 | loss: 1.5879 | lr: 9.7488e-05, scale: 262144.0000 | grad_norm: 1.1059\cb1 \
\cb3 2023-07-12 12:52:19 | Iter: 35000 | loss: 1.5912 | lr: 9.7478e-05, scale: 262144.0000 | grad_norm: 1.0745\cb1 \
\cb3 start valid!\cb1 \
\cb3 2023-07-12 12:52:38 | Iter: 35000 | valid loss: 1.5349\cb1 \
\cb3 saving status into: /data/checkpoints/checkpoint-35000.success\cb1 \
\cb3 Saving checkpoint at 35000 step.\cb1 \
\cb3 2023-07-12 12:55:03 | Iter: 35100 | loss: 1.5934 | lr: 9.7468e-05, scale: 262144.0000 | grad_norm: 1.0711\cb1 \
\cb3 2023-07-12 12:57:16 | Iter: 35200 | loss: 1.5952 | lr: 9.7458e-05, scale: 262144.0000 | grad_norm: 1.0736\cb1 \
\cb3 2023-07-12 12:59:31 | Iter: 35300 | loss: 1.5804 | lr: 9.7448e-05, scale: 262144.0000 | grad_norm: 1.0726\cb1 \
\cb3 2023-07-12 13:01:45 | Iter: 35400 | loss: 1.5911 | lr: 9.7438e-05, scale: 262144.0000 | grad_norm: 1.1358\cb1 \
\cb3 2023-07-12 13:03:58 | Iter: 35500 | loss: 1.5817 | lr: 9.7427e-05, scale: 262144.0000 | grad_norm: 1.1211\cb1 \
\cb3 start valid!\cb1 \
\cb3 2023-07-12 13:04:15 | Iter: 35500 | valid loss: 1.5399\cb1 \
\cb3 saving status into: /data/checkpoints/checkpoint-35500.success\cb1 \
\cb3 Saving checkpoint at 35500 step.\cb1 \
\cb3 2023-07-12 13:06:44 | Iter: 35600 | loss: 1.5843 | lr: 9.7417e-05, scale: 262144.0000 | grad_norm: 1.0578\cb1 \
\cb3 2023-07-12 13:08:58 | Iter: 35700 | loss: 1.5795 | lr: 9.7407e-05, scale: 262144.0000 | grad_norm: 1.0450\cb1 \
\cb3 Gradient overflow, change scale from 524288.000000 to 262144.000000\cb1 \
\cb3 2023-07-12 13:11:13 | Iter: 35800 | loss: 1.5820 | lr: 9.7397e-05, scale: 262144.0000 | grad_norm: 1.0081\cb1 \
\cb3 2023-07-12 13:13:28 | Iter: 35900 | loss: 1.5812 | lr: 9.7387e-05, scale: 262144.0000 | grad_norm: 1.0576\cb1 \
\cb3 2023-07-12 13:15:44 | Iter: 36000 | loss: 1.5776 | lr: 9.7377e-05, scale: 262144.0000 | grad_norm: 1.0741\cb1 \
\cb3 start valid!\cb1 \
\cb3 2023-07-12 13:16:00 | Iter: 36000 | valid loss: 1.5337\cb1 \
\cb3 saving status into: /data/checkpoints/checkpoint-36000.success\cb1 \
\cb3 Saving checkpoint at 36000 step.\cb1 \
\cb3 2023-07-12 13:18:25 | Iter: 36100 | loss: 1.5799 | lr: 9.7367e-05, scale: 262144.0000 | grad_norm: 1.0526\cb1 \
\cb3 2023-07-12 13:20:41 | Iter: 36200 | loss: 1.5875 | lr: 9.7357e-05, scale: 262144.0000 | grad_norm: 1.0634\cb1 \
\cb3 2023-07-12 13:22:58 | Iter: 36300 | loss: 1.5727 | lr: 9.7347e-05, scale: 262144.0000 | grad_norm: 1.0737\cb1 \
\cb3 2023-07-12 13:25:11 | Iter: 36400 | loss: 1.5707 | lr: 9.7337e-05, scale: 262144.0000 | grad_norm: 1.0808\cb1 \
\cb3 2023-07-12 13:27:27 | Iter: 36500 | loss: 1.5737 | lr: 9.7327e-05, scale: 262144.0000 | grad_norm: 1.0644\cb1 \
\cb3 start valid!\cb1 \
\cb3 2023-07-12 13:27:44 | Iter: 36500 | valid loss: 1.5086\cb1 \
\cb3 saving status into: /data/checkpoints/checkpoint-36500.success\cb1 \
\cb3 Saving checkpoint at 36500 step.\cb1 \
\cb3 2023-07-12 13:30:11 | Iter: 36600 | loss: 1.5676 | lr: 9.7316e-05, scale: 262144.0000 | grad_norm: 1.0756\cb1 \
\cb3 2023-07-12 13:32:24 | Iter: 36700 | loss: 1.5758 | lr: 9.7306e-05, scale: 262144.0000 | grad_norm: 1.1405\cb1 \
\cb3 2023-07-12 13:34:39 | Iter: 36800 | loss: 1.5716 | lr: 9.7296e-05, scale: 262144.0000 | grad_norm: 1.0599\cb1 \
\cb3 Gradient overflow, change scale from 524288.000000 to 262144.000000\cb1 \
\cb3 2023-07-12 13:36:54 | Iter: 36900 | loss: 1.5695 | lr: 9.7286e-05, scale: 262144.0000 | grad_norm: 1.0580\cb1 \
\cb3 Gradient overflow, change scale from 262144.000000 to 131072.000000\cb1 \
\cb3 2023-07-12 13:39:09 | Iter: 37000 | loss: 1.5633 | lr: 9.7276e-05, scale: 131072.0000 | grad_norm: 1.0734\cb1 \
\cb3 start valid!\cb1 \
\cb3 2023-07-12 13:39:25 | Iter: 37000 | valid loss: 1.5053\cb1 \
\cb3 saving status into: /data/checkpoints/checkpoint-37000.success\cb1 \
\cb3 Saving checkpoint at 37000 step.\cb1 \
\cb3 2023-07-12 13:41:55 | Iter: 37100 | loss: 1.5673 | lr: 9.7266e-05, scale: 131072.0000 | grad_norm: 1.0402\cb1 \
\cb3 2023-07-12 13:44:08 | Iter: 37200 | loss: 1.5744 | lr: 9.7256e-05, scale: 131072.0000 | grad_norm: 1.0692\cb1 \
\cb3 2023-07-12 13:46:24 | Iter: 37300 | loss: 1.5730 | lr: 9.7246e-05, scale: 131072.0000 | grad_norm: 1.0754\cb1 \
\cb3 2023-07-12 13:48:38 | Iter: 37400 | loss: 1.5674 | lr: 9.7236e-05, scale: 131072.0000 | grad_norm: 1.1106\cb1 \
\cb3 2023-07-12 13:50:50 | Iter: 37500 | loss: 1.5614 | lr: 9.7226e-05, scale: 131072.0000 | grad_norm: 1.0985\cb1 \
\cb3 start valid!\cb1 \
\cb3 2023-07-12 13:51:06 | Iter: 37500 | valid loss: 1.5160\cb1 \
\cb3 saving status into: /data/checkpoints/checkpoint-37500.success\cb1 \
\cb3 Saving checkpoint at 37500 step.\cb1 \
\cb3 2023-07-12 13:53:32 | Iter: 37600 | loss: 1.5584 | lr: 9.7216e-05, scale: 131072.0000 | grad_norm: 1.0823\cb1 \
\cb3 2023-07-12 13:55:47 | Iter: 37700 | loss: 1.5618 | lr: 9.7206e-05, scale: 131072.0000 | grad_norm: 1.0707\cb1 \
\cb3 2023-07-12 13:58:01 | Iter: 37800 | loss: 1.5621 | lr: 9.7195e-05, scale: 131072.0000 | grad_norm: 1.0418\cb1 \
\cb3 2023-07-12 14:00:13 | Iter: 37900 | loss: 1.5659 | lr: 9.7185e-05, scale: 131072.0000 | grad_norm: 1.0659\cb1 \
\cb3 2023-07-12 14:02:30 | Iter: 38000 | loss: 1.5577 | lr: 9.7175e-05, scale: 262144.0000 | grad_norm: 0.8713\cb1 \
\cb3 start valid!\cb1 \
\cb3 2023-07-12 14:02:48 | Iter: 38000 | valid loss: 1.4973\cb1 \
\cb3 saving status into: /data/checkpoints/checkpoint-38000.success\cb1 \
\cb3 Saving checkpoint at 38000 step.\cb1 \
\cb3 2023-07-12 14:05:13 | Iter: 38100 | loss: 1.5500 | lr: 9.7165e-05, scale: 262144.0000 | grad_norm: 1.0745\cb1 \
\cb3 Gradient overflow, change scale from 262144.000000 to 131072.000000\cb1 \
\cb3 2023-07-12 14:07:27 | Iter: 38200 | loss: 1.5501 | lr: 9.7155e-05, scale: 131072.0000 | grad_norm: 1.0329\cb1 \
\cb3 2023-07-12 14:09:41 | Iter: 38300 | loss: 1.5559 | lr: 9.7145e-05, scale: 131072.0000 | grad_norm: 1.0828\cb1 \
\cb3 2023-07-12 14:11:56 | Iter: 38400 | loss: 1.5624 | lr: 9.7135e-05, scale: 131072.0000 | grad_norm: 1.0537\cb1 \
\cb3 2023-07-12 14:14:09 | Iter: 38500 | loss: 1.5626 | lr: 9.7125e-05, scale: 131072.0000 | grad_norm: 1.0869\cb1 \
\cb3 start valid!\cb1 \
\cb3 2023-07-12 14:14:25 | Iter: 38500 | valid loss: 1.5095\cb1 \
\cb3 saving status into: /data/checkpoints/checkpoint-38500.success\cb1 \
\cb3 Saving checkpoint at 38500 step.\cb1 \
\cb3 2023-07-12 14:16:52 | Iter: 38600 | loss: 1.5524 | lr: 9.7115e-05, scale: 131072.0000 | grad_norm: 1.0469\cb1 \
\cb3 2023-07-12 14:19:04 | Iter: 38700 | loss: 1.5594 | lr: 9.7105e-05, scale: 131072.0000 | grad_norm: 1.0748\cb1 \
\cb3 2023-07-12 14:21:18 | Iter: 38800 | loss: 1.5597 | lr: 9.7095e-05, scale: 131072.0000 | grad_norm: 1.0857\cb1 \
\cb3 2023-07-12 14:23:32 | Iter: 38900 | loss: 1.5483 | lr: 9.7084e-05, scale: 131072.0000 | grad_norm: 1.0705\cb1 \
\cb3 2023-07-12 14:25:46 | Iter: 39000 | loss: 1.5496 | lr: 9.7074e-05, scale: 131072.0000 | grad_norm: 1.0496\cb1 \
\cb3 start valid!\cb1 \
\cb3 2023-07-12 14:26:02 | Iter: 39000 | valid loss: 1.4932\cb1 \
\cb3 saving status into: /data/checkpoints/checkpoint-39000.success\cb1 \
\cb3 Saving checkpoint at 39000 step.\cb1 \
\cb3 2023-07-12 14:28:30 | Iter: 39100 | loss: 1.5527 | lr: 9.7064e-05, scale: 131072.0000 | grad_norm: 1.1208\cb1 \
\cb3 Gradient overflow, change scale from 262144.000000 to 131072.000000\cb1 \
\cb3 2023-07-12 14:30:46 | Iter: 39200 | loss: 1.5381 | lr: 9.7054e-05, scale: 131072.0000 | grad_norm: 1.0404\cb1 \
\cb3 2023-07-12 14:33:01 | Iter: 39300 | loss: 1.5535 | lr: 9.7044e-05, scale: 131072.0000 | grad_norm: 1.0652\cb1 \
\cb3 2023-07-12 14:35:14 | Iter: 39400 | loss: 1.5454 | lr: 9.7034e-05, scale: 131072.0000 | grad_norm: 1.0576\cb1 \
\cb3 2023-07-12 14:37:29 | Iter: 39500 | loss: 1.5471 | lr: 9.7024e-05, scale: 131072.0000 | grad_norm: 1.0681\cb1 \
\cb3 start valid!\cb1 \
\cb3 2023-07-12 14:37:46 | Iter: 39500 | valid loss: 1.4878\cb1 \
\cb3 saving status into: /data/checkpoints/checkpoint-39500.success\cb1 \
\cb3 Saving checkpoint at 39500 step.\cb1 \
\cb3 2023-07-12 14:40:12 | Iter: 39600 | loss: 1.5409 | lr: 9.7014e-05, scale: 131072.0000 | grad_norm: 1.0574\cb1 \
\cb3 2023-07-12 14:42:27 | Iter: 39700 | loss: 1.5461 | lr: 9.7004e-05, scale: 131072.0000 | grad_norm: 1.0915\cb1 \
\cb3 2023-07-12 14:44:39 | Iter: 39800 | loss: 1.5420 | lr: 9.6994e-05, scale: 131072.0000 | grad_norm: 1.0572\cb1 \
\cb3 2023-07-12 14:46:54 | Iter: 39900 | loss: 1.5473 | lr: 9.6984e-05, scale: 131072.0000 | grad_norm: 1.0442\cb1 \
\cb3 2023-07-12 14:49:08 | Iter: 40000 | loss: 1.5446 | lr: 9.6973e-05, scale: 131072.0000 | grad_norm: 1.0616\cb1 \
\cb3 start valid!\cb1 \
\cb3 2023-07-12 14:49:24 | Iter: 40000 | valid loss: 1.4927\cb1 \
\cb3 saving status into: /data/checkpoints/checkpoint-40000.success\cb1 \
\cb3 Saving checkpoint at 40000 step.\cb1 \
\cb3 2023-07-12 14:51:52 | Iter: 40100 | loss: 1.5459 | lr: 9.6963e-05, scale: 131072.0000 | grad_norm: 1.0472\cb1 \
\cb3 Gradient overflow, change scale from 262144.000000 to 131072.000000\cb1 \
\cb3 2023-07-12 14:54:07 | Iter: 40200 | loss: 1.5327 | lr: 9.6953e-05, scale: 131072.0000 | grad_norm: 1.0267\cb1 \
\cb3 2023-07-12 14:56:20 | Iter: 40300 | loss: 1.5417 | lr: 9.6943e-05, scale: 131072.0000 | grad_norm: 1.0308\cb1 \
\cb3 2023-07-12 14:58:34 | Iter: 40400 | loss: 1.5329 | lr: 9.6933e-05, scale: 131072.0000 | grad_norm: 1.0624\cb1 \
\cb3 2023-07-12 15:00:46 | Iter: 40500 | loss: 1.5354 | lr: 9.6923e-05, scale: 131072.0000 | grad_norm: 1.0549\cb1 \
\cb3 start valid!\cb1 \
\cb3 2023-07-12 15:01:03 | Iter: 40500 | valid loss: 1.4863\cb1 \
\cb3 saving status into: /data/checkpoints/checkpoint-40500.success\cb1 \
\cb3 Saving checkpoint at 40500 step.\cb1 \
\cb3 2023-07-12 15:03:31 | Iter: 40600 | loss: 1.5360 | lr: 9.6913e-05, scale: 131072.0000 | grad_norm: 1.0405\cb1 \
\cb3 2023-07-12 15:05:46 | Iter: 40700 | loss: 1.5357 | lr: 9.6903e-05, scale: 131072.0000 | grad_norm: 1.0669\cb1 \
\cb3 2023-07-12 15:08:00 | Iter: 40800 | loss: 1.5412 | lr: 9.6893e-05, scale: 131072.0000 | grad_norm: 1.0443\cb1 \
\cb3 2023-07-12 15:10:14 | Iter: 40900 | loss: 1.5421 | lr: 9.6883e-05, scale: 131072.0000 | grad_norm: 1.0504\cb1 \
\cb3 2023-07-12 15:12:27 | Iter: 41000 | loss: 1.5356 | lr: 9.6873e-05, scale: 131072.0000 | grad_norm: 1.0595\cb1 \
\cb3 start valid!\cb1 \
\cb3 2023-07-12 15:12:45 | Iter: 41000 | valid loss: 1.4714\cb1 \
\cb3 saving status into: /data/checkpoints/checkpoint-41000.success\cb1 \
\cb3 Saving checkpoint at 41000 step.\cb1 \
\cb3 2023-07-12 15:15:13 | Iter: 41100 | loss: 1.5346 | lr: 9.6862e-05, scale: 131072.0000 | grad_norm: 1.0646\cb1 \
\cb3 2023-07-12 15:17:29 | Iter: 41200 | loss: 1.5312 | lr: 9.6852e-05, scale: 131072.0000 | grad_norm: 1.0975\cb1 \
\cb3 Gradient overflow, change scale from 262144.000000 to 131072.000000\cb1 \
\cb3 2023-07-12 15:19:44 | Iter: 41300 | loss: 1.5195 | lr: 9.6842e-05, scale: 131072.0000 | grad_norm: 1.1300\cb1 \
\cb3 2023-07-12 15:22:00 | Iter: 41400 | loss: 1.5237 | lr: 9.6832e-05, scale: 131072.0000 | grad_norm: 1.0708\cb1 \
\cb3 2023-07-12 15:24:14 | Iter: 41500 | loss: 1.5245 | lr: 9.6822e-05, scale: 131072.0000 | grad_norm: 1.0468\cb1 \
\cb3 start valid!\cb1 \
\cb3 2023-07-12 15:24:31 | Iter: 41500 | valid loss: 1.4891\cb1 \
\cb3 saving status into: /data/checkpoints/checkpoint-41500.success\cb1 \
\cb3 Saving checkpoint at 41500 step.\cb1 \
\cb3 2023-07-12 15:26:58 | Iter: 41600 | loss: 1.5365 | lr: 9.6812e-05, scale: 131072.0000 | grad_norm: 1.0586\cb1 \
\cb3 2023-07-12 15:29:12 | Iter: 41700 | loss: 1.5271 | lr: 9.6802e-05, scale: 131072.0000 | grad_norm: 1.0589\cb1 \
\cb3 2023-07-12 15:31:25 | Iter: 41800 | loss: 1.5268 | lr: 9.6792e-05, scale: 131072.0000 | grad_norm: 1.0416\cb1 \
\cb3 2023-07-12 15:33:39 | Iter: 41900 | loss: 1.5286 | lr: 9.6782e-05, scale: 131072.0000 | grad_norm: 1.0631\cb1 \
\cb3 2023-07-12 15:35:53 | Iter: 42000 | loss: 1.5242 | lr: 9.6772e-05, scale: 131072.0000 | grad_norm: 1.0761\cb1 \
\cb3 start valid!\cb1 \
\cb3 2023-07-12 15:36:09 | Iter: 42000 | valid loss: 1.4698\cb1 \
\cb3 saving status into: /data/checkpoints/checkpoint-42000.success\cb1 \
\cb3 Saving checkpoint at 42000 step.\cb1 \
\cb3 2023-07-12 15:38:38 | Iter: 42100 | loss: 1.5240 | lr: 9.6762e-05, scale: 131072.0000 | grad_norm: 1.0385\cb1 \
\cb3 2023-07-12 15:40:52 | Iter: 42200 | loss: 1.5271 | lr: 9.6751e-05, scale: 131072.0000 | grad_norm: 1.0586\cb1 \
\cb3 2023-07-12 15:43:06 | Iter: 42300 | loss: 1.5276 | lr: 9.6741e-05, scale: 262144.0000 | grad_norm: 1.0487\cb1 \
\cb3 2023-07-12 15:45:20 | Iter: 42400 | loss: 1.5226 | lr: 9.6731e-05, scale: 262144.0000 | grad_norm: 1.0608\cb1 \
\cb3 Gradient overflow, change scale from 262144.000000 to 131072.000000\cb1 \
\cb3 2023-07-12 15:47:37 | Iter: 42500 | loss: 1.5125 | lr: 9.6721e-05, scale: 131072.0000 | grad_norm: 1.1143\cb1 \
\cb3 start valid!\cb1 \
\cb3 2023-07-12 15:47:53 | Iter: 42500 | valid loss: 1.4816\cb1 \
\cb3 saving status into: /data/checkpoints/checkpoint-42500.success\cb1 \
\cb3 Saving checkpoint at 42500 step.\cb1 \
\cb3 2023-07-12 15:50:20 | Iter: 42600 | loss: 1.5131 | lr: 9.6711e-05, scale: 131072.0000 | grad_norm: 1.0563\cb1 \
\cb3 2023-07-12 15:52:37 | Iter: 42700 | loss: 1.5166 | lr: 9.6701e-05, scale: 131072.0000 | grad_norm: 1.0537\cb1 \
\cb3 2023-07-12 15:54:49 | Iter: 42800 | loss: 1.5160 | lr: 9.6691e-05, scale: 131072.0000 | grad_norm: 1.0349\cb1 \
\cb3 2023-07-12 15:57:02 | Iter: 42900 | loss: 1.5166 | lr: 9.6681e-05, scale: 131072.0000 | grad_norm: 1.0414\cb1 \
\cb3 2023-07-12 15:59:16 | Iter: 43000 | loss: 1.5129 | lr: 9.6671e-05, scale: 131072.0000 | grad_norm: 1.0774\cb1 \
\cb3 start valid!\cb1 \
\cb3 2023-07-12 15:59:32 | Iter: 43000 | valid loss: 1.4642\cb1 \
\cb3 saving status into: /data/checkpoints/checkpoint-43000.success\cb1 \
\cb3 Saving checkpoint at 43000 step.\cb1 \
\cb3 2023-07-12 16:02:01 | Iter: 43100 | loss: 1.5116 | lr: 9.6661e-05, scale: 131072.0000 | grad_norm: 1.0313\cb1 \
\cb3 2023-07-12 16:04:18 | Iter: 43200 | loss: 1.5148 | lr: 9.6651e-05, scale: 131072.0000 | grad_norm: 1.0371\cb1 \
\cb3 2023-07-12 16:06:36 | Iter: 43300 | loss: 1.5143 | lr: 9.6640e-05, scale: 131072.0000 | grad_norm: 1.0386\cb1 \
\cb3 2023-07-12 16:08:48 | Iter: 43400 | loss: 1.5068 | lr: 9.6630e-05, scale: 131072.0000 | grad_norm: 1.0122\cb1 \
\cb3 2023-07-12 16:11:03 | Iter: 43500 | loss: 1.5144 | lr: 9.6620e-05, scale: 262144.0000 | grad_norm: 1.0418\cb1 \
\cb3 start valid!\cb1 \
\cb3 2023-07-12 16:11:19 | Iter: 43500 | valid loss: 1.4576\cb1 \
\cb3 saving status into: /data/checkpoints/checkpoint-43500.success\cb1 \
\cb3 Saving checkpoint at 43500 step.\cb1 \
\cb3 2023-07-12 16:13:47 | Iter: 43600 | loss: 1.5188 | lr: 9.6610e-05, scale: 262144.0000 | grad_norm: 1.0575\cb1 \
\cb3 2023-07-12 16:15:59 | Iter: 43700 | loss: 1.5149 | lr: 9.6600e-05, scale: 262144.0000 | grad_norm: 1.0537\cb1 \
\cb3 2023-07-12 16:18:12 | Iter: 43800 | loss: 1.5164 | lr: 9.6590e-05, scale: 262144.0000 | grad_norm: 1.0488\cb1 \
\cb3 2023-07-12 16:20:28 | Iter: 43900 | loss: 1.5136 | lr: 9.6580e-05, scale: 262144.0000 | grad_norm: 1.0649\cb1 \
\cb3 2023-07-12 16:22:44 | Iter: 44000 | loss: 1.5118 | lr: 9.6570e-05, scale: 262144.0000 | grad_norm: 1.0551\cb1 \
\cb3 start valid!\cb1 \
\cb3 2023-07-12 16:23:00 | Iter: 44000 | valid loss: 1.4560\cb1 \
\cb3 saving status into: /data/checkpoints/checkpoint-44000.success\cb1 \
\cb3 Saving checkpoint at 44000 step.\cb1 \
\cb3 2023-07-12 16:25:28 | Iter: 44100 | loss: 1.5081 | lr: 9.6560e-05, scale: 262144.0000 | grad_norm: 1.0420\cb1 \
\cb3 2023-07-12 16:27:43 | Iter: 44200 | loss: 1.4968 | lr: 9.6549e-05, scale: 262144.0000 | grad_norm: 1.0628\cb1 \
\cb3 2023-07-12 16:29:58 | Iter: 44300 | loss: 1.5074 | lr: 9.6539e-05, scale: 262144.0000 | grad_norm: 1.0595\cb1 \
\cb3 2023-07-12 16:32:13 | Iter: 44400 | loss: 1.5026 | lr: 9.6529e-05, scale: 262144.0000 | grad_norm: 1.0206\cb1 \
\cb3 Gradient overflow, change scale from 262144.000000 to 131072.000000\cb1 \
\cb3 2023-07-12 16:34:27 | Iter: 44500 | loss: 1.4975 | lr: 9.6519e-05, scale: 131072.0000 | grad_norm: 1.0391\cb1 \
\cb3 start valid!\cb1 \
\cb3 2023-07-12 16:34:43 | Iter: 44500 | valid loss: 1.4354\cb1 \
\cb3 saving status into: /data/checkpoints/checkpoint-44500.success\cb1 \
\cb3 Saving checkpoint at 44500 step.\cb1 \
\cb3 2023-07-12 16:37:09 | Iter: 44600 | loss: 1.5062 | lr: 9.6509e-05, scale: 131072.0000 | grad_norm: 1.0793\cb1 \
\cb3 2023-07-12 16:39:22 | Iter: 44700 | loss: 1.5048 | lr: 9.6499e-05, scale: 131072.0000 | grad_norm: 1.0557\cb1 \
\cb3 2023-07-12 16:41:36 | Iter: 44800 | loss: 1.5011 | lr: 9.6489e-05, scale: 131072.0000 | grad_norm: 1.0576\cb1 \
\cb3 2023-07-12 16:43:52 | Iter: 44900 | loss: 1.5046 | lr: 9.6479e-05, scale: 131072.0000 | grad_norm: 1.0610\cb1 \
\cb3 2023-07-12 16:46:06 | Iter: 45000 | loss: 1.5069 | lr: 9.6469e-05, scale: 131072.0000 | grad_norm: 1.0939\cb1 \
\cb3 start valid!\cb1 \
\cb3 2023-07-12 16:46:20 | Iter: 45000 | valid loss: 1.4638\cb1 \
\cb3 saving status into: /data/checkpoints/checkpoint-45000.success\cb1 \
\cb3 Saving checkpoint at 45000 step.\cb1 \
\cb3 2023-07-12 16:48:49 | Iter: 45100 | loss: 1.5039 | lr: 9.6459e-05, scale: 131072.0000 | grad_norm: 1.0670\cb1 \
\cb3 2023-07-12 16:51:04 | Iter: 45200 | loss: 1.5010 | lr: 9.6449e-05, scale: 131072.0000 | grad_norm: 1.0268\cb1 \
\cb3 2023-07-12 16:53:17 | Iter: 45300 | loss: 1.5051 | lr: 9.6438e-05, scale: 131072.0000 | grad_norm: 1.0637\cb1 \
\cb3 2023-07-12 16:55:34 | Iter: 45400 | loss: 1.4970 | lr: 9.6428e-05, scale: 131072.0000 | grad_norm: 1.0522\cb1 \
\cb3 2023-07-12 16:57:49 | Iter: 45500 | loss: 1.4875 | lr: 9.6418e-05, scale: 262144.0000 | grad_norm: 1.0556\cb1 \
\cb3 start valid!\cb1 \
\cb3 2023-07-12 16:58:04 | Iter: 45500 | valid loss: 1.4428\cb1 \
\cb3 saving status into: /data/checkpoints/checkpoint-45500.success\cb1 \
\cb3 Saving checkpoint at 45500 step.\cb1 \
\cb3 2023-07-12 17:00:32 | Iter: 45600 | loss: 1.4887 | lr: 9.6408e-05, scale: 262144.0000 | grad_norm: 1.0429\cb1 \
\cb3 2023-07-12 17:02:46 | Iter: 45700 | loss: 1.4938 | lr: 9.6398e-05, scale: 262144.0000 | grad_norm: 1.0613\cb1 \
\cb3 2023-07-12 17:04:59 | Iter: 45800 | loss: 1.4979 | lr: 9.6388e-05, scale: 262144.0000 | grad_norm: 1.0508\cb1 \
\cb3 Gradient overflow, change scale from 262144.000000 to 131072.000000\cb1 \
\cb3 2023-07-12 17:07:15 | Iter: 45900 | loss: 1.4966 | lr: 9.6378e-05, scale: 131072.0000 | grad_norm: 1.0384\cb1 \
\cb3 2023-07-12 17:09:28 | Iter: 46000 | loss: 1.4923 | lr: 9.6368e-05, scale: 131072.0000 | grad_norm: 1.0349\cb1 \
\cb3 start valid!\cb1 \
\cb3 2023-07-12 17:09:44 | Iter: 46000 | valid loss: 1.4467\cb1 \
\cb3 saving status into: /data/checkpoints/checkpoint-46000.success\cb1 \
\cb3 Saving checkpoint at 46000 step.\cb1 \
\cb3 2023-07-12 17:12:11 | Iter: 46100 | loss: 1.4949 | lr: 9.6358e-05, scale: 131072.0000 | grad_norm: 1.0747\cb1 \
\cb3 2023-07-12 17:14:26 | Iter: 46200 | loss: 1.4888 | lr: 9.6348e-05, scale: 131072.0000 | grad_norm: 1.0511\cb1 \
\cb3 2023-07-12 17:16:41 | Iter: 46300 | loss: 1.4943 | lr: 9.6338e-05, scale: 131072.0000 | grad_norm: 1.0667\cb1 \
\cb3 2023-07-12 17:18:57 | Iter: 46400 | loss: 1.4873 | lr: 9.6327e-05, scale: 131072.0000 | grad_norm: 1.0473\cb1 \
\cb3 2023-07-12 17:21:11 | Iter: 46500 | loss: 1.4880 | lr: 9.6317e-05, scale: 131072.0000 | grad_norm: 1.0694\cb1 \
\cb3 start valid!\cb1 \
\cb3 2023-07-12 17:21:28 | Iter: 46500 | valid loss: 1.4483\cb1 \
\cb3 saving status into: /data/checkpoints/checkpoint-46500.success\cb1 \
\cb3 Saving checkpoint at 46500 step.\cb1 \
\cb3 2023-07-12 17:23:54 | Iter: 46600 | loss: 1.4887 | lr: 9.6307e-05, scale: 131072.0000 | grad_norm: 1.1064\cb1 \
\cb3 2023-07-12 17:26:08 | Iter: 46700 | loss: 1.4810 | lr: 9.6297e-05, scale: 131072.0000 | grad_norm: 1.0630\cb1 \
\cb3 2023-07-12 17:28:21 | Iter: 46800 | loss: 1.4885 | lr: 9.6287e-05, scale: 131072.0000 | grad_norm: 1.0231\cb1 \
\cb3 2023-07-12 17:30:37 | Iter: 46900 | loss: 1.4759 | lr: 9.6277e-05, scale: 262144.0000 | grad_norm: 1.0910\cb1 \
\cb3 Gradient overflow, change scale from 262144.000000 to 131072.000000\cb1 \
\cb3 2023-07-12 17:32:52 | Iter: 47000 | loss: 1.4798 | lr: 9.6267e-05, scale: 131072.0000 | grad_norm: 1.0504\cb1 \
\cb3 start valid!\cb1 \
\cb3 2023-07-12 17:33:07 | Iter: 47000 | valid loss: 1.4265\cb1 \
\cb3 saving status into: /data/checkpoints/checkpoint-47000.success\cb1 \
\cb3 Saving checkpoint at 47000 step.\cb1 \
\cb3 2023-07-12 17:35:34 | Iter: 47100 | loss: 1.4878 | lr: 9.6257e-05, scale: 131072.0000 | grad_norm: 1.0434\cb1 \
\cb3 2023-07-12 17:37:51 | Iter: 47200 | loss: 1.4816 | lr: 9.6247e-05, scale: 131072.0000 | grad_norm: 1.0283\cb1 \
\cb3 2023-07-12 17:40:03 | Iter: 47300 | loss: 1.4862 | lr: 9.6237e-05, scale: 131072.0000 | grad_norm: 1.0469\cb1 \
\cb3 2023-07-12 17:42:18 | Iter: 47400 | loss: 1.4847 | lr: 9.6227e-05, scale: 131072.0000 | grad_norm: 1.0657\cb1 \
\cb3 2023-07-12 17:44:32 | Iter: 47500 | loss: 1.4784 | lr: 9.6216e-05, scale: 131072.0000 | grad_norm: 1.0486\cb1 \
\cb3 start valid!\cb1 \
\cb3 2023-07-12 17:44:47 | Iter: 47500 | valid loss: 1.4346\cb1 \
\cb3 saving status into: /data/checkpoints/checkpoint-47500.success\cb1 \
\cb3 Saving checkpoint at 47500 step.\cb1 \
\cb3 2023-07-12 17:47:13 | Iter: 47600 | loss: 1.4875 | lr: 9.6206e-05, scale: 131072.0000 | grad_norm: 1.0521\cb1 \
\cb3 2023-07-12 17:49:27 | Iter: 47700 | loss: 1.4840 | lr: 9.6196e-05, scale: 131072.0000 | grad_norm: 1.0294\cb1 \
\cb3 2023-07-12 17:51:41 | Iter: 47800 | loss: 1.4774 | lr: 9.6186e-05, scale: 131072.0000 | grad_norm: 1.0417\cb1 \
\cb3 2023-07-12 17:53:55 | Iter: 47900 | loss: 1.4763 | lr: 9.6176e-05, scale: 131072.0000 | grad_norm: 1.0387\cb1 \
\cb3 2023-07-12 17:56:10 | Iter: 48000 | loss: 1.4753 | lr: 9.6166e-05, scale: 262144.0000 | grad_norm: 1.0273\cb1 \
\cb3 start valid!\cb1 \
\cb3 2023-07-12 17:56:26 | Iter: 48000 | valid loss: 1.4217\cb1 \
\cb3 saving status into: /data/checkpoints/checkpoint-48000.success\cb1 \
\cb3 Saving checkpoint at 48000 step.\cb1 \
\cb3 2023-07-12 17:58:54 | Iter: 48100 | loss: 1.4866 | lr: 9.6156e-05, scale: 262144.0000 | grad_norm: 1.0648\cb1 \
\cb3 2023-07-12 18:01:07 | Iter: 48200 | loss: 1.4762 | lr: 9.6146e-05, scale: 262144.0000 | grad_norm: 1.0443\cb1 \
\cb3 2023-07-12 18:03:22 | Iter: 48300 | loss: 1.4749 | lr: 9.6136e-05, scale: 262144.0000 | grad_norm: 1.0499\cb1 \
\cb3 2023-07-12 18:05:40 | Iter: 48400 | loss: 1.4758 | lr: 9.6126e-05, scale: 262144.0000 | grad_norm: 1.0877\cb1 \
\cb3 Gradient overflow, change scale from 262144.000000 to 131072.000000\cb1 \
\cb3 2023-07-12 18:07:56 | Iter: 48500 | loss: 1.4661 | lr: 9.6116e-05, scale: 131072.0000 | grad_norm: 1.0495\cb1 \
\cb3 start valid!\cb1 \
\cb3 2023-07-12 18:08:11 | Iter: 48500 | valid loss: 1.4219\cb1 \
\cb3 saving status into: /data/checkpoints/checkpoint-48500.success\cb1 \
\cb3 Saving checkpoint at 48500 step.\cb1 \
\cb3 2023-07-12 18:10:37 | Iter: 48600 | loss: 1.4690 | lr: 9.6105e-05, scale: 131072.0000 | grad_norm: 1.0285\cb1 \
\cb3 2023-07-12 18:12:50 | Iter: 48700 | loss: 1.4750 | lr: 9.6095e-05, scale: 131072.0000 | grad_norm: 1.0277\cb1 \
\cb3 2023-07-12 18:15:05 | Iter: 48800 | loss: 1.4706 | lr: 9.6085e-05, scale: 131072.0000 | grad_norm: 1.0333\cb1 \
\cb3 2023-07-12 18:17:18 | Iter: 48900 | loss: 1.4714 | lr: 9.6075e-05, scale: 131072.0000 | grad_norm: 1.0466\cb1 \
\cb3 2023-07-12 18:19:32 | Iter: 49000 | loss: 1.4643 | lr: 9.6065e-05, scale: 131072.0000 | grad_norm: 1.0274\cb1 \
\cb3 start valid!\cb1 \
\cb3 2023-07-12 18:19:47 | Iter: 49000 | valid loss: 1.4289\cb1 \
\cb3 saving status into: /data/checkpoints/checkpoint-49000.success\cb1 \
\cb3 Saving checkpoint at 49000 step.\cb1 \
\cb3 2023-07-12 18:22:13 | Iter: 49100 | loss: 1.4751 | lr: 9.6055e-05, scale: 131072.0000 | grad_norm: 1.0473\cb1 \
\cb3 2023-07-12 18:24:28 | Iter: 49200 | loss: 1.4643 | lr: 9.6045e-05, scale: 131072.0000 | grad_norm: 1.0159\cb1 \
\cb3 2023-07-12 18:26:44 | Iter: 49300 | loss: 1.4635 | lr: 9.6035e-05, scale: 131072.0000 | grad_norm: 1.0674\cb1 \
\cb3 2023-07-12 18:28:58 | Iter: 49400 | loss: 1.4668 | lr: 9.6025e-05, scale: 131072.0000 | grad_norm: 1.0362\cb1 \
\cb3 2023-07-12 18:31:11 | Iter: 49500 | loss: 1.4683 | lr: 9.6015e-05, scale: 262144.0000 | grad_norm: 1.0521\cb1 \
\cb3 start valid!\cb1 \
\cb3 2023-07-12 18:31:27 | Iter: 49500 | valid loss: 1.4197\cb1 \
\cb3 saving status into: /data/checkpoints/checkpoint-49500.success\cb1 \
\cb3 Saving checkpoint at 49500 step.}